{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad276cb3-8364-45ed-b858-bf3bf67088e0",
   "metadata": {},
   "source": [
    "# Applied Machine Learning Project 1 : Classification using Logistic Regression Models\n",
    "**Srinath Murali Krishnan | NetID:SMK220008**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e4d64c-3667-43fc-ab37-c2092e2bbb2c",
   "metadata": {},
   "source": [
    "# Data Importing and Preliminary Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f59db98-0856-4c74-b86c-ffcc0e3fcbe8",
   "metadata": {},
   "source": [
    "1) We first import the data and identify the target variable\n",
    "2) We describe the data and observe column values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "2964421e-7218-4299-a7f0-90863c70da5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "f711bede-9327-4047-858f-284ce6128cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dataset\n",
    "X_train = pd.read_csv('SBA_loans_project_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "d27ca6ce-9159-4e1b-ad27-ca4645d608c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop('index',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "d3e68785-cc1e-4680-b0ba-09f342608d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_more(df,normalize_ind=False, weight_column=None, skip_columns=[], dropna=True):\n",
    "    var = [] ; l = [] ; t = []; unq =[]; min_l = []; max_l = [];\n",
    "    assert isinstance(skip_columns, list), \"Argument skip_columns should be list\"\n",
    "    if weight_column is not None:\n",
    "        if weight_column not in list(df.columns):\n",
    "            raise AssertionError('weight_column is not a valid column name in the input X_trainFrame')\n",
    "      \n",
    "    for x in df:\n",
    "        if x in skip_columns:\n",
    "            pass\n",
    "        else:\n",
    "            var.append( x )\n",
    "            uniq_counts = len(pd.value_counts(df[x],dropna=dropna))\n",
    "            uniq_counts = len(pd.value_counts(df[x], dropna=dropna)[pd.value_counts(df[x],dropna=dropna)>0])\n",
    "            l.append(uniq_counts)\n",
    "            t.append( df[ x ].dtypes )\n",
    "            min_l.append(df[x].apply(str).str.len().min())\n",
    "            max_l.append(df[x].apply(str).str.len().max())\n",
    "            if weight_column is not None and x not in skip_columns:\n",
    "                df2 = df.groupby(x).agg({weight_column: 'sum'}).sort_values(weight_column, ascending=False)\n",
    "                df2['authtrans_vts_cnt']=((df2[weight_column])/df2[weight_column].sum()).round(2)\n",
    "                unq.append(df2.head(n=100).to_dict()[weight_column])\n",
    "            else:\n",
    "                df_cat_d = df[x].value_counts(normalize=normalize_ind,dropna=dropna).round(decimals=2)\n",
    "                df_cat_d = df_cat_d[df_cat_d>0]\n",
    "                #unq.append(df[x].value_counts().iloc[0:100].to_dict())\n",
    "                unq.append(df_cat_d.iloc[0:200].to_dict())\n",
    "                \n",
    "            \n",
    "    levels = pd.DataFrame( { 'A_Variable' : var , 'Levels' : l , 'X_traintype' : t ,\n",
    "                             'Min Length' : min_l,\n",
    "                             'Max Length': max_l,\n",
    "                             'Level_Values' : unq} )\n",
    "    #levels.sort_values( by = 'Levels' , inplace = True )\n",
    "    return levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "b60c2e6a-dbb0-4331-bb5d-a3d474b25a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=describe_more(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "44551720-2a85-474f-a547-a45f728ebe21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A_Variable</th>\n",
       "      <th>Levels</th>\n",
       "      <th>X_traintype</th>\n",
       "      <th>Min Length</th>\n",
       "      <th>Max Length</th>\n",
       "      <th>Level_Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>City</td>\n",
       "      <td>31090</td>\n",
       "      <td>object</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>{'LOS ANGELES': 10265, 'HOUSTON': 9166, 'NEW Y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>State</td>\n",
       "      <td>51</td>\n",
       "      <td>object</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>{'CA': 116234, 'TX': 62648, 'NY': 51520, 'FL':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Zip</td>\n",
       "      <td>32655</td>\n",
       "      <td>int64</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>{10001: 843, 90015: 816, 93401: 702, 90010: 64...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bank</td>\n",
       "      <td>5690</td>\n",
       "      <td>object</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>{'BANK OF AMERICA NATL ASSOC': 77280, 'WELLS F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BankState</td>\n",
       "      <td>55</td>\n",
       "      <td>object</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>{'CA': 105036, 'NC': 70727, 'IL': 58662, 'OH':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NAICS</td>\n",
       "      <td>1306</td>\n",
       "      <td>int64</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>{0: 179808, 722110: 24960, 722211: 17305, 8111...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NoEmp</td>\n",
       "      <td>579</td>\n",
       "      <td>int64</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>{1: 137210, 2: 123131, 3: 80793, 4: 65687, 5: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NewExist</td>\n",
       "      <td>3</td>\n",
       "      <td>float64</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>{1.0: 573786, 2.0: 225426, 0.0: 922}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CreateJob</td>\n",
       "      <td>230</td>\n",
       "      <td>int64</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>{0: 560211, 1: 56249, 2: 51419, 3: 25670, 4: 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RetainedJob</td>\n",
       "      <td>346</td>\n",
       "      <td>int64</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>{0: 392105, 1: 78963, 2: 68443, 3: 44463, 4: 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>FranchiseCode</td>\n",
       "      <td>2683</td>\n",
       "      <td>int64</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>{1: 568329, 0: 185783, 78760: 2988, 68020: 170...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>UrbanRural</td>\n",
       "      <td>3</td>\n",
       "      <td>int64</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{1: 418792, 0: 287637, 2: 93826}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RevLineCr</td>\n",
       "      <td>17</td>\n",
       "      <td>object</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>{'N': 374209, '0': 229202, 'Y': 179202, 'T': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LowDoc</td>\n",
       "      <td>8</td>\n",
       "      <td>object</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>{'N': 696572, 'Y': 98366, '0': 1310, 'C': 666,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DisbursementGross</td>\n",
       "      <td>109860</td>\n",
       "      <td>float64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>{50000.0: 38939, 100000.0: 32679, 25000.0: 243...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>BalanceGross</td>\n",
       "      <td>13</td>\n",
       "      <td>float64</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>{0.0: 800243, 115820.0: 1, 96908.0: 1, 43127.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>GrAppv</td>\n",
       "      <td>20615</td>\n",
       "      <td>float64</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>{50000.0: 61710, 25000.0: 45606, 100000.0: 453...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SBA_Appv</td>\n",
       "      <td>35681</td>\n",
       "      <td>float64</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>{25000.0: 44045, 12500.0: 35731, 5000.0: 27613...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MIS_Status</td>\n",
       "      <td>2</td>\n",
       "      <td>int64</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{0: 660075, 1: 140180}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           A_Variable  Levels X_traintype  Min Length  Max Length  \\\n",
       "0                City   31090      object           1          30   \n",
       "1               State      51      object           2           3   \n",
       "2                 Zip   32655       int64           1           5   \n",
       "3                Bank    5690      object           3          30   \n",
       "4           BankState      55      object           2           3   \n",
       "5               NAICS    1306       int64           1           6   \n",
       "6               NoEmp     579       int64           1           4   \n",
       "7            NewExist       3     float64           3           3   \n",
       "8           CreateJob     230       int64           1           4   \n",
       "9         RetainedJob     346       int64           1           4   \n",
       "10      FranchiseCode    2683       int64           1           5   \n",
       "11         UrbanRural       3       int64           1           1   \n",
       "12          RevLineCr      17      object           1           3   \n",
       "13             LowDoc       8      object           1           3   \n",
       "14  DisbursementGross  109860     float64           3          10   \n",
       "15       BalanceGross      13     float64           3           8   \n",
       "16             GrAppv   20615     float64           5           9   \n",
       "17           SBA_Appv   35681     float64           5           9   \n",
       "18         MIS_Status       2       int64           1           1   \n",
       "\n",
       "                                         Level_Values  \n",
       "0   {'LOS ANGELES': 10265, 'HOUSTON': 9166, 'NEW Y...  \n",
       "1   {'CA': 116234, 'TX': 62648, 'NY': 51520, 'FL':...  \n",
       "2   {10001: 843, 90015: 816, 93401: 702, 90010: 64...  \n",
       "3   {'BANK OF AMERICA NATL ASSOC': 77280, 'WELLS F...  \n",
       "4   {'CA': 105036, 'NC': 70727, 'IL': 58662, 'OH':...  \n",
       "5   {0: 179808, 722110: 24960, 722211: 17305, 8111...  \n",
       "6   {1: 137210, 2: 123131, 3: 80793, 4: 65687, 5: ...  \n",
       "7                {1.0: 573786, 2.0: 225426, 0.0: 922}  \n",
       "8   {0: 560211, 1: 56249, 2: 51419, 3: 25670, 4: 1...  \n",
       "9   {0: 392105, 1: 78963, 2: 68443, 3: 44463, 4: 3...  \n",
       "10  {1: 568329, 0: 185783, 78760: 2988, 68020: 170...  \n",
       "11                   {1: 418792, 0: 287637, 2: 93826}  \n",
       "12  {'N': 374209, '0': 229202, 'Y': 179202, 'T': 1...  \n",
       "13  {'N': 696572, 'Y': 98366, '0': 1310, 'C': 666,...  \n",
       "14  {50000.0: 38939, 100000.0: 32679, 25000.0: 243...  \n",
       "15  {0.0: 800243, 115820.0: 1, 96908.0: 1, 43127.0...  \n",
       "16  {50000.0: 61710, 25000.0: 45606, 100000.0: 453...  \n",
       "17  {25000.0: 44045, 12500.0: 35731, 5000.0: 27613...  \n",
       "18                             {0: 660075, 1: 140180}  "
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76c51b3-b0d1-4f14-8753-df683d1524ca",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Cleaning Step:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b5b7ba-3c4b-435c-b08d-2ed32f841fa3",
   "metadata": {},
   "source": [
    "1) The strategy of data cleaning is to identify extra characters in columns that may or may not have just 2 viables characters such as RevLineCr and LowDoc with 'Y' and 'N'\n",
    "2) we identify the context of the extra characters and replace them with Y and N respectively\n",
    "3) if the character has no contextual backing, we convert them to null values\n",
    "4) Final step involves identifying columns with null values and replacing them with imputed values in the corresponding column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "083e0dc1-d381-43dc-b889-129fbc61d0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing values in RevLineCr with Y and N\n",
    "X_train['RevLineCr']=X_train['RevLineCr'].replace('0','N')\n",
    "X_train['RevLineCr']=X_train['RevLineCr'].replace('1','Y')\n",
    "X_train['RevLineCr']=X_train['RevLineCr'].replace('T','Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "b3a08d56-9039-47de-ba07-3ef9ef936936",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing values in RevLineCr with null that have no context\n",
    "X_train['RevLineCr'] = X_train['RevLineCr'].apply(lambda x: x if x in ['Y', 'N'] else np.nan)\n",
    "\n",
    "\n",
    "X_train['RevLineCr'].fillna(X_train['RevLineCr'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "f97a129a-dc1e-4648-ad03-7954adf5efec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing values in LowDoc with Y and N\n",
    "X_train['LowDoc']=X_train['LowDoc'].replace('0','N')\n",
    "X_train['LowDoc']=X_train['LowDoc'].replace('S','Y')\n",
    "X_train['LowDoc']=X_train['LowDoc'].replace('A','N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "383e4b3f-a4d7-4307-8696-189dbca16fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing values in LowDoc with null that have no context\n",
    "X_train['LowDoc'] = X_train['LowDoc'].apply(lambda x: x if x in ['Y', 'N'] else np.nan)\n",
    "\n",
    "\n",
    "X_train['LowDoc'].fillna(X_train['LowDoc'].mode()[0], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "c5a32aba-9f19-49e4-af49-416dd2835e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining target variable\n",
    "y_train = X_train['MIS_Status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "4ad0c5d6-66ed-4719-8500-7038262ec099",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=y_train.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "1e232ba4-723c-4c22-bd36-70f362ca2ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop('MIS_Status',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "91c10175-b62b-4d9e-bec3-00a5d439b262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A_Variable</th>\n",
       "      <th>Levels</th>\n",
       "      <th>X_traintype</th>\n",
       "      <th>Min Length</th>\n",
       "      <th>Max Length</th>\n",
       "      <th>Level_Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>City</td>\n",
       "      <td>31090</td>\n",
       "      <td>object</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>{'LOS ANGELES': 10265, 'HOUSTON': 9166, 'NEW Y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>State</td>\n",
       "      <td>51</td>\n",
       "      <td>object</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>{'CA': 116234, 'TX': 62648, 'NY': 51520, 'FL':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Zip</td>\n",
       "      <td>32655</td>\n",
       "      <td>int64</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>{10001: 843, 90015: 816, 93401: 702, 90010: 64...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bank</td>\n",
       "      <td>5690</td>\n",
       "      <td>object</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>{'BANK OF AMERICA NATL ASSOC': 77280, 'WELLS F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BankState</td>\n",
       "      <td>55</td>\n",
       "      <td>object</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>{'CA': 105036, 'NC': 70727, 'IL': 58662, 'OH':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NAICS</td>\n",
       "      <td>1306</td>\n",
       "      <td>int64</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>{0: 179808, 722110: 24960, 722211: 17305, 8111...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NoEmp</td>\n",
       "      <td>579</td>\n",
       "      <td>int64</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>{1: 137210, 2: 123131, 3: 80793, 4: 65687, 5: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NewExist</td>\n",
       "      <td>3</td>\n",
       "      <td>float64</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>{1.0: 573786, 2.0: 225426, 0.0: 922}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CreateJob</td>\n",
       "      <td>230</td>\n",
       "      <td>int64</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>{0: 560211, 1: 56249, 2: 51419, 3: 25670, 4: 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RetainedJob</td>\n",
       "      <td>346</td>\n",
       "      <td>int64</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>{0: 392105, 1: 78963, 2: 68443, 3: 44463, 4: 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>FranchiseCode</td>\n",
       "      <td>2683</td>\n",
       "      <td>int64</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>{1: 568329, 0: 185783, 78760: 2988, 68020: 170...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>UrbanRural</td>\n",
       "      <td>3</td>\n",
       "      <td>int64</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{1: 418792, 0: 287637, 2: 93826}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RevLineCr</td>\n",
       "      <td>2</td>\n",
       "      <td>object</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'N': 607491, 'Y': 192764}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LowDoc</td>\n",
       "      <td>2</td>\n",
       "      <td>object</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'N': 701359, 'Y': 98896}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DisbursementGross</td>\n",
       "      <td>109860</td>\n",
       "      <td>float64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>{50000.0: 38939, 100000.0: 32679, 25000.0: 243...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>BalanceGross</td>\n",
       "      <td>13</td>\n",
       "      <td>float64</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>{0.0: 800243, 115820.0: 1, 96908.0: 1, 43127.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>GrAppv</td>\n",
       "      <td>20615</td>\n",
       "      <td>float64</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>{50000.0: 61710, 25000.0: 45606, 100000.0: 453...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SBA_Appv</td>\n",
       "      <td>35681</td>\n",
       "      <td>float64</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>{25000.0: 44045, 12500.0: 35731, 5000.0: 27613...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           A_Variable  Levels X_traintype  Min Length  Max Length  \\\n",
       "0                City   31090      object           1          30   \n",
       "1               State      51      object           2           3   \n",
       "2                 Zip   32655       int64           1           5   \n",
       "3                Bank    5690      object           3          30   \n",
       "4           BankState      55      object           2           3   \n",
       "5               NAICS    1306       int64           1           6   \n",
       "6               NoEmp     579       int64           1           4   \n",
       "7            NewExist       3     float64           3           3   \n",
       "8           CreateJob     230       int64           1           4   \n",
       "9         RetainedJob     346       int64           1           4   \n",
       "10      FranchiseCode    2683       int64           1           5   \n",
       "11         UrbanRural       3       int64           1           1   \n",
       "12          RevLineCr       2      object           1           1   \n",
       "13             LowDoc       2      object           1           1   \n",
       "14  DisbursementGross  109860     float64           3          10   \n",
       "15       BalanceGross      13     float64           3           8   \n",
       "16             GrAppv   20615     float64           5           9   \n",
       "17           SBA_Appv   35681     float64           5           9   \n",
       "\n",
       "                                         Level_Values  \n",
       "0   {'LOS ANGELES': 10265, 'HOUSTON': 9166, 'NEW Y...  \n",
       "1   {'CA': 116234, 'TX': 62648, 'NY': 51520, 'FL':...  \n",
       "2   {10001: 843, 90015: 816, 93401: 702, 90010: 64...  \n",
       "3   {'BANK OF AMERICA NATL ASSOC': 77280, 'WELLS F...  \n",
       "4   {'CA': 105036, 'NC': 70727, 'IL': 58662, 'OH':...  \n",
       "5   {0: 179808, 722110: 24960, 722211: 17305, 8111...  \n",
       "6   {1: 137210, 2: 123131, 3: 80793, 4: 65687, 5: ...  \n",
       "7                {1.0: 573786, 2.0: 225426, 0.0: 922}  \n",
       "8   {0: 560211, 1: 56249, 2: 51419, 3: 25670, 4: 1...  \n",
       "9   {0: 392105, 1: 78963, 2: 68443, 3: 44463, 4: 3...  \n",
       "10  {1: 568329, 0: 185783, 78760: 2988, 68020: 170...  \n",
       "11                   {1: 418792, 0: 287637, 2: 93826}  \n",
       "12                         {'N': 607491, 'Y': 192764}  \n",
       "13                          {'N': 701359, 'Y': 98896}  \n",
       "14  {50000.0: 38939, 100000.0: 32679, 25000.0: 243...  \n",
       "15  {0.0: 800243, 115820.0: 1, 96908.0: 1, 43127.0...  \n",
       "16  {50000.0: 61710, 25000.0: 45606, 100000.0: 453...  \n",
       "17  {25000.0: 44045, 12500.0: 35731, 5000.0: 27613...  "
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "describe_more(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "7ddf24f6-8e45-4dc8-8981-b8135a55f4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imputing null values\n",
    "cat=['City','State','Bank','BankState']\n",
    "num=['NewExist']\n",
    "for i in cat:\n",
    "    X_train[i].fillna(X_train[i].mode().iloc[0],inplace=True)\n",
    "for i in num:\n",
    "    X_train[i].fillna(X_train[i].median(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "bcd26786-9bae-45b5-b6db-78580fff01ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if any columns still have null values\n",
    "cat=[]\n",
    "for col in X_train.columns:\n",
    "    if X_train[col].isna().any() == True:\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110df3d6-83b7-43ca-bf69-2646099336be",
   "metadata": {},
   "source": [
    "# Feature Engineering step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75e82c8-f0df-4d4f-93a7-6f32702e4a6f",
   "metadata": {},
   "source": [
    "1) We construct 10 new features from the existing features in the dataset\n",
    "2) The task is to create better features packed with more contextual information\n",
    "3) We further use VIF for feature selection and getting rid of any possible multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "8b182814-4442-46be-a21c-283b82138f34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"X=X_train.copy()\\ngeo_concentration = data['State'].value_counts(normalize=True)\\ndata['geo_concentration'] = data['State'].map(geo_concentration)\""
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"X=X_train.copy()\n",
    "geo_concentration = data['State'].value_counts(normalize=True)\n",
    "data['geo_concentration'] = data['State'].map(geo_concentration)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "37e1bd6d-31ba-4cca-9e7e-19992b2e62e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'X_train' is your X_trainFrame and already includes basic preprocessing\n",
    "\n",
    "# Feature 1: Loan Size Category\n",
    "X_train['LoanSizeCategory'] = pd.cut(X_train['GrAppv'], bins=[0, 50000, 150000, 350000, 1000000, 5000000], labels=['Micro', 'Small', 'Medium', 'Large', 'Very Large'])\n",
    "\n",
    "# Feature 2: Job Creation Category\n",
    "X_train['JobCreationCategory'] = pd.cut(X_train['CreateJob'] + X_train['RetainedJob'], bins=[-1, 0, 5, 10, 20, 50, 100, float('inf')], labels=['None', 'Few', 'Some', 'Moderate', 'Many', 'A Lot', 'Massive'])\n",
    "\n",
    "# Feature 3: High-Risk Industry (NAICxS codes starting with 72 are typically hospitality, considered higher risk)\n",
    "X_train['HighRiskIndustry'] = X_train['NAICS'].apply(lambda x: 1 if str(x).startswith('72') else 0)\n",
    "\n",
    "# Feature 4: Loan/Grant Ratio\n",
    "X_train['LoanGrantRatio'] = X_train['GrAppv'] / X_train['SBA_Appv']\n",
    "\n",
    "# Feature 5: Per Employee Investment\n",
    "X_train['PerEmployeeInvestment'] = X_train['GrAppv'] / (X_train['NoEmp'] + 1)  # Avoid division by zero\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "4f72486e-befa-4214-b0e4-0962c5baa79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Feature 6: Business Age - New business flag (assuming NewExist codes: 1 for existing, 2 for new)\n",
    "X_train['NewBusiness'] = X_train['NewExist'].apply(lambda x: 1 if x == 2 else 0)\n",
    "\n",
    "# Feature 7: Urban Business - Flag for businesses in urban areas (assuming UrbanRural codes: 1 for urban, 2 for rural, 0 for undefined)\n",
    "X_train['UrbanBusiness'] = X_train['UrbanRural'].apply(lambda x: 1 if x == 1 else 0)\n",
    "\n",
    "# Feature 8: Franchise Flag - Flag for whether the business is a franchise (assuming FranchiseCode: 1 or 0 indicates not a franchise, any other value indicates a franchise)\n",
    "X_train['FranchiseFlag'] = X_train['FranchiseCode'].apply(lambda x: 0 if x == 1 or x == 0 else 1)\n",
    "\n",
    "# Feature 9: Expansion Plan - Flag businesses creating more jobs than retaining (CreateJob > RetainedJob)\n",
    "X_train['ExpansionPlan'] = X_train.apply(lambda x: 1 if x['CreateJob'] > x['RetainedJob'] else 0, axis=1)\n",
    "\n",
    "# Feature 10: Economic Sector - Extract broader economic sector from NAICS code (first two digits of NAICS code)\n",
    "X_train['EconomicSector'] = X_train['NAICS'].apply(lambda x: int(str(x)[:2]) if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "c534ddb7-eb08-428a-ab6a-e7927df438db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Zip</th>\n",
       "      <th>Bank</th>\n",
       "      <th>BankState</th>\n",
       "      <th>NAICS</th>\n",
       "      <th>NoEmp</th>\n",
       "      <th>NewExist</th>\n",
       "      <th>CreateJob</th>\n",
       "      <th>RetainedJob</th>\n",
       "      <th>...</th>\n",
       "      <th>LoanSizeCategory</th>\n",
       "      <th>JobCreationCategory</th>\n",
       "      <th>HighRiskIndustry</th>\n",
       "      <th>LoanGrantRatio</th>\n",
       "      <th>PerEmployeeInvestment</th>\n",
       "      <th>NewBusiness</th>\n",
       "      <th>UrbanBusiness</th>\n",
       "      <th>FranchiseFlag</th>\n",
       "      <th>ExpansionPlan</th>\n",
       "      <th>EconomicSector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>APPLETON</td>\n",
       "      <td>WI</td>\n",
       "      <td>59414</td>\n",
       "      <td>ASSOCIATED BANK NATL ASSOC</td>\n",
       "      <td>WI</td>\n",
       "      <td>321918</td>\n",
       "      <td>26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Small</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>3703.703704</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WEATHERFORD</td>\n",
       "      <td>TX</td>\n",
       "      <td>76086</td>\n",
       "      <td>REGIONS BANK</td>\n",
       "      <td>AL</td>\n",
       "      <td>621391</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>Small</td>\n",
       "      <td>Few</td>\n",
       "      <td>0</td>\n",
       "      <td>1.176471</td>\n",
       "      <td>48733.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FLORENCE</td>\n",
       "      <td>SC</td>\n",
       "      <td>29505</td>\n",
       "      <td>SUPERIOR FINANCIAL GROUP, LLC</td>\n",
       "      <td>CA</td>\n",
       "      <td>236220</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>Micro</td>\n",
       "      <td>Some</td>\n",
       "      <td>0</td>\n",
       "      <td>1.176471</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BOSTON</td>\n",
       "      <td>MA</td>\n",
       "      <td>2124</td>\n",
       "      <td>CITIZENS BANK NATL ASSOC</td>\n",
       "      <td>RI</td>\n",
       "      <td>236115</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>Small</td>\n",
       "      <td>Few</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>12500.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LAFAYETTE</td>\n",
       "      <td>IN</td>\n",
       "      <td>47904</td>\n",
       "      <td>THE HUNTINGTON NATIONAL BANK</td>\n",
       "      <td>OH</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Small</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>963.855422</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800250</th>\n",
       "      <td>FAIRFIELD</td>\n",
       "      <td>OH</td>\n",
       "      <td>45014</td>\n",
       "      <td>ACCESS BUS. DEVEL &amp; FINANCE IN</td>\n",
       "      <td>OH</td>\n",
       "      <td>235920</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Small</td>\n",
       "      <td>Few</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>36250.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800251</th>\n",
       "      <td>COHOES</td>\n",
       "      <td>NY</td>\n",
       "      <td>12047</td>\n",
       "      <td>EMPIRE ST. CERT. DEVEL CORP</td>\n",
       "      <td>NY</td>\n",
       "      <td>541430</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Few</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18000.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800252</th>\n",
       "      <td>MANSFIELD</td>\n",
       "      <td>MA</td>\n",
       "      <td>2048</td>\n",
       "      <td>BANK OF AMERICA NATL ASSOC</td>\n",
       "      <td>RI</td>\n",
       "      <td>722320</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>Micro</td>\n",
       "      <td>Few</td>\n",
       "      <td>1</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2500.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800253</th>\n",
       "      <td>WALLINGTON</td>\n",
       "      <td>NJ</td>\n",
       "      <td>7057</td>\n",
       "      <td>VALLEY NATIONAL BANK</td>\n",
       "      <td>NJ</td>\n",
       "      <td>447110</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>Large</td>\n",
       "      <td>Some</td>\n",
       "      <td>0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>130000.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800254</th>\n",
       "      <td>CLEVELAND</td>\n",
       "      <td>OH</td>\n",
       "      <td>44115</td>\n",
       "      <td>UNITED MIDWEST SAVINGS BANK</td>\n",
       "      <td>OH</td>\n",
       "      <td>722110</td>\n",
       "      <td>47</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Large</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>10687.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800255 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               City State    Zip                            Bank BankState  \\\n",
       "0          APPLETON    WI  59414      ASSOCIATED BANK NATL ASSOC        WI   \n",
       "1       WEATHERFORD    TX  76086                    REGIONS BANK        AL   \n",
       "2          FLORENCE    SC  29505   SUPERIOR FINANCIAL GROUP, LLC        CA   \n",
       "3            BOSTON    MA   2124        CITIZENS BANK NATL ASSOC        RI   \n",
       "4         LAFAYETTE    IN  47904    THE HUNTINGTON NATIONAL BANK        OH   \n",
       "...             ...   ...    ...                             ...       ...   \n",
       "800250    FAIRFIELD    OH  45014  ACCESS BUS. DEVEL & FINANCE IN        OH   \n",
       "800251       COHOES    NY  12047     EMPIRE ST. CERT. DEVEL CORP        NY   \n",
       "800252    MANSFIELD    MA   2048      BANK OF AMERICA NATL ASSOC        RI   \n",
       "800253   WALLINGTON    NJ   7057            VALLEY NATIONAL BANK        NJ   \n",
       "800254    CLEVELAND    OH  44115     UNITED MIDWEST SAVINGS BANK        OH   \n",
       "\n",
       "         NAICS  NoEmp  NewExist  CreateJob  RetainedJob  ...  \\\n",
       "0       321918     26       1.0          0            0  ...   \n",
       "1       621391      2       1.0          1            3  ...   \n",
       "2       236220      3       1.0          3            3  ...   \n",
       "3       236115      5       1.0          0            5  ...   \n",
       "4            0     82       1.0          0            0  ...   \n",
       "...        ...    ...       ...        ...          ...  ...   \n",
       "800250  235920      3       1.0          5            0  ...   \n",
       "800251  541430     10       1.0          0            1  ...   \n",
       "800252  722320      3       1.0          0            3  ...   \n",
       "800253  447110      3       1.0          3            3  ...   \n",
       "800254  722110     47       1.0          0            0  ...   \n",
       "\n",
       "        LoanSizeCategory  JobCreationCategory HighRiskIndustry LoanGrantRatio  \\\n",
       "0                  Small                 None                0       1.250000   \n",
       "1                  Small                  Few                0       1.176471   \n",
       "2                  Micro                 Some                0       1.176471   \n",
       "3                  Small                  Few                0       2.000000   \n",
       "4                  Small                 None                0       1.250000   \n",
       "...                  ...                  ...              ...            ...   \n",
       "800250             Small                  Few                0       1.000000   \n",
       "800251            Medium                  Few                0       1.000000   \n",
       "800252             Micro                  Few                1       2.000000   \n",
       "800253             Large                 Some                0       1.333333   \n",
       "800254             Large                 None                1       1.333333   \n",
       "\n",
       "        PerEmployeeInvestment  NewBusiness  UrbanBusiness  FranchiseFlag  \\\n",
       "0                 3703.703704            0              0              0   \n",
       "1                48733.333333            0              1              0   \n",
       "2                 5000.000000            0              1              0   \n",
       "3                12500.000000            0              1              0   \n",
       "4                  963.855422            0              0              0   \n",
       "...                       ...          ...            ...            ...   \n",
       "800250           36250.000000            0              0              0   \n",
       "800251           18000.000000            0              1              0   \n",
       "800252            2500.000000            0              1              0   \n",
       "800253          130000.000000            0              1              0   \n",
       "800254           10687.500000            0              1              0   \n",
       "\n",
       "       ExpansionPlan EconomicSector  \n",
       "0                  0             32  \n",
       "1                  0             62  \n",
       "2                  0             23  \n",
       "3                  0             23  \n",
       "4                  0              0  \n",
       "...              ...            ...  \n",
       "800250             1             23  \n",
       "800251             0             54  \n",
       "800252             0             72  \n",
       "800253             0             44  \n",
       "800254             0             72  \n",
       "\n",
       "[800255 rows x 28 columns]"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "a5806cfd-fe78-463a-bc80-b99ab667b516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert columns fo category type to object \n",
    "for col in X_train.select_dtypes(include=['category']).columns:\n",
    "    X_train[col] = X_train[col].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "2833dd6e-d920-422d-862d-5d09384e01f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "9bba00ad-c736-4e9b-a4e7-5a57909b5918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the vif for all given features\n",
    "def compute_vif(considered_features):\n",
    "    \n",
    "    X = X_train[considered_features]\n",
    "    # the calculation of variance inflation requires a constant\n",
    "    X['intercept'] = 1\n",
    "    \n",
    "    # create dataframe to store vif values\n",
    "    vif = pd.DataFrame()\n",
    "    vif[\"Variable\"] = X.columns\n",
    "    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "    vif = vif[vif['Variable']!='intercept']\n",
    "    return vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "e2883080-d991-43d5-8ee2-7af5b0271091",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x3/5n0yyb7911zg532jx71xlkrr0000gn/T/ipykernel_89675/3288876314.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['intercept'] = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>VIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Zip</td>\n",
       "      <td>1.027956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NAICS</td>\n",
       "      <td>14568.940812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NoEmp</td>\n",
       "      <td>1.024878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NewExist</td>\n",
       "      <td>177.651526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CreateJob</td>\n",
       "      <td>95.305460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RetainedJob</td>\n",
       "      <td>95.298903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FranchiseCode</td>\n",
       "      <td>4.220769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>UrbanRural</td>\n",
       "      <td>1.517659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DisbursementGross</td>\n",
       "      <td>18.197366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BalanceGross</td>\n",
       "      <td>1.000068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GrAppv</td>\n",
       "      <td>44.050688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SBA_Appv</td>\n",
       "      <td>25.786152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>HighRiskIndustry</td>\n",
       "      <td>1.230341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LoanGrantRatio</td>\n",
       "      <td>1.815665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PerEmployeeInvestment</td>\n",
       "      <td>1.502093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NewBusiness</td>\n",
       "      <td>177.798742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>UrbanBusiness</td>\n",
       "      <td>1.476246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>FranchiseFlag</td>\n",
       "      <td>4.268697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ExpansionPlan</td>\n",
       "      <td>1.163964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>EconomicSector</td>\n",
       "      <td>14532.028853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Variable           VIF\n",
       "0                     Zip      1.027956\n",
       "1                   NAICS  14568.940812\n",
       "2                   NoEmp      1.024878\n",
       "3                NewExist    177.651526\n",
       "4               CreateJob     95.305460\n",
       "5             RetainedJob     95.298903\n",
       "6           FranchiseCode      4.220769\n",
       "7              UrbanRural      1.517659\n",
       "8       DisbursementGross     18.197366\n",
       "9            BalanceGross      1.000068\n",
       "10                 GrAppv     44.050688\n",
       "11               SBA_Appv     25.786152\n",
       "12       HighRiskIndustry      1.230341\n",
       "13         LoanGrantRatio      1.815665\n",
       "14  PerEmployeeInvestment      1.502093\n",
       "15            NewBusiness    177.798742\n",
       "16          UrbanBusiness      1.476246\n",
       "17          FranchiseFlag      4.268697\n",
       "18          ExpansionPlan      1.163964\n",
       "19         EconomicSector  14532.028853"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_vif(numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "28ef3d45-9dee-4115-a20e-4bf8da4acbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "drops=['NewExist','CreateJob','RetainedJob','NAICS','GrAppv','SBA_Appv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "aacfecfc-0728-42d7-bff2-6ad1481013ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x3/5n0yyb7911zg532jx71xlkrr0000gn/T/ipykernel_89675/3288876314.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['intercept'] = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>VIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Zip</td>\n",
       "      <td>1.027287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NoEmp</td>\n",
       "      <td>1.020546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FranchiseCode</td>\n",
       "      <td>4.220009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UrbanRural</td>\n",
       "      <td>1.426755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DisbursementGross</td>\n",
       "      <td>1.484929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BalanceGross</td>\n",
       "      <td>1.000066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HighRiskIndustry</td>\n",
       "      <td>1.210052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LoanGrantRatio</td>\n",
       "      <td>1.445532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PerEmployeeInvestment</td>\n",
       "      <td>1.451915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NewBusiness</td>\n",
       "      <td>1.078733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>UrbanBusiness</td>\n",
       "      <td>1.439242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>FranchiseFlag</td>\n",
       "      <td>4.265352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ExpansionPlan</td>\n",
       "      <td>1.093707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>EconomicSector</td>\n",
       "      <td>1.498528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Variable       VIF\n",
       "0                     Zip  1.027287\n",
       "1                   NoEmp  1.020546\n",
       "2           FranchiseCode  4.220009\n",
       "3              UrbanRural  1.426755\n",
       "4       DisbursementGross  1.484929\n",
       "5            BalanceGross  1.000066\n",
       "6        HighRiskIndustry  1.210052\n",
       "7          LoanGrantRatio  1.445532\n",
       "8   PerEmployeeInvestment  1.451915\n",
       "9             NewBusiness  1.078733\n",
       "10          UrbanBusiness  1.439242\n",
       "11          FranchiseFlag  4.265352\n",
       "12          ExpansionPlan  1.093707\n",
       "13         EconomicSector  1.498528"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = [item for item in numeric if item not in drops]\n",
    "compute_vif(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2360ad-577c-425e-a697-2d641442db07",
   "metadata": {},
   "source": [
    "# Data Encoding Step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9522a4-2f6a-4568-a15f-17c26ba1e1a5",
   "metadata": {},
   "source": [
    "1) This step involves identifying the numerical and categorical columns: a) for one hot and b) woe encoding\n",
    "2) The categorical columns undergo encoding based on whether they have less than 10 values or not\n",
    "3) further we scale the numerical columns\n",
    "4) we save the encoders/scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "35872687-645c-46e2-b2d6-bb2452bd1fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "# Assuming 'X_train' is the X_trainFrame after feature engineering\n",
    "# Assuming 'target' is the name of the target column in 'X_train'\n",
    "\n",
    "# Identify categorical variables with less than 10 unique values for one-hot encoding\n",
    "cat_vars_for_one_hot = [col for col in X_train.columns if (X_train[col].nunique() < 10) and (X_train[col].dtype == 'object')]\n",
    "\n",
    "# Now, for target and WOE encoding, identify the remaining categorical variables\n",
    "remaining_cat_vars = [col for col in X_train.columns if (X_train[col].dtype == 'object') and (col not in cat_vars_for_one_hot)]\n",
    "\n",
    "numeric=[col for col in X_train.columns if (X_train[col].dtype != 'object') ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "393cc3d0-da53-4950-9e3a-f5b978117ca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RevLineCr', 'LowDoc', 'LoanSizeCategory', 'JobCreationCategory']"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_vars_for_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "57649dee-c1c2-487b-b8ff-afa4d2d9ab9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['City', 'State', 'Bank', 'BankState']"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remaining_cat_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "b10bd75c-c117-4dce-96a2-8cc7dcbc7bd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Zip',\n",
       " 'NAICS',\n",
       " 'NoEmp',\n",
       " 'NewExist',\n",
       " 'CreateJob',\n",
       " 'RetainedJob',\n",
       " 'FranchiseCode',\n",
       " 'UrbanRural',\n",
       " 'DisbursementGross',\n",
       " 'BalanceGross',\n",
       " 'GrAppv',\n",
       " 'SBA_Appv',\n",
       " 'HighRiskIndustry',\n",
       " 'LoanGrantRatio',\n",
       " 'PerEmployeeInvestment',\n",
       " 'NewBusiness',\n",
       " 'UrbanBusiness',\n",
       " 'FranchiseFlag',\n",
       " 'ExpansionPlan',\n",
       " 'EconomicSector']"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "5b421b2b-3d30-496c-8dfe-c33b19739300",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "# using the train test split function\n",
    "x_train, x_val, y_t, y_val = train_test_split(\n",
    "  X_train,y_train , random_state=104,test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "82e736db-3791-4593-bf41-9b370973a3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize WOE encoder for categorical variables\n",
    "woe_encoder = ce.WOEEncoder(cols=remaining_cat_vars)\n",
    "\n",
    "# Fit the WOE encoder on the training data\n",
    "# Assuming 'target' is the name of your target variable in the training data\n",
    "woe_encoder.fit(x_train[remaining_cat_vars], y_t)\n",
    "\n",
    "# Transform the training and validation data using the fitted encoder\n",
    "x_train = x_train.join(woe_encoder.transform(x_train[remaining_cat_vars]).add_suffix('_woe'))\n",
    "x_val = x_val.join(woe_encoder.transform(x_val[remaining_cat_vars]).add_suffix('_woe'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "24006950-484f-472c-95a3-1270f10ea8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "5c087a31-c92a-46f5-a9cc-2d7b1116bbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Standard Scaler to Scale the numerical columns\n",
    "scaler = StandardScaler()\n",
    "# Fit the scaler on the training data\n",
    "scaler.fit(x_train[res])\n",
    "# Transform the training and validation data using the fitted scaler\n",
    "x_train[res] = scaler.transform(x_train[res])\n",
    "x_val[res] = scaler.transform(x_val[res])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "26256862-88fc-4a72-8d24-2e2800f6149b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Assuming woe_encoder is your fitted encoder\n",
    "with open('woe_encoder.pkl', 'wb') as file:\n",
    "    pickle.dump(woe_encoder, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "8c1fcdd4-4ab8-4217-b1ff-ea37259a88ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming scaler is your fitted scaler\n",
    "with open('standardscaler.pkl', 'wb') as file:\n",
    "    pickle.dump(scaler, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "fc87685c-c434-4f40-b903-e0ea5f85da61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the unencoded columns\n",
    "x_train.drop(columns=remaining_cat_vars,axis=1,inplace=True)\n",
    "x_train.drop(columns=drops,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "9774fbc9-4e97-4bc4-bccc-81eebf663e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#steps repeated for validation\n",
    "x_val.drop(columns=remaining_cat_vars,axis=1,inplace=True)\n",
    "x_val.drop(columns=drops,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "503e61ff-ef27-4ad8-8a3e-0458961ca33f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(drop='first', sparse=False)"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "# Initialize the OneHotEncoder\n",
    "ohe_encoder = OneHotEncoder(sparse=False, drop='first')  # `drop='first'` to drop the first category to avoid multicollinearity\n",
    "# LoanSizeCategory: Column Dropped is LoanSizeCategoryLarge\n",
    "# JobCreationCategory: Column Dropped is JobCreationCategoryFew\n",
    "# RevLineCr: Column Dropped is RevLineCrN\n",
    "# LowDoc: Column Dropped is LowDocN\n",
    "\n",
    "# Fit the encoder on the training data\n",
    "ohe_encoder.fit(x_train[cat_vars_for_one_hot])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "ba18208a-5a85-43ef-a04d-c9c4f3ea8e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_ohe = ohe_encoder.transform(x_train[cat_vars_for_one_hot])\n",
    "# Convert to DataFrame and name columns\n",
    "columns = ohe_encoder.get_feature_names_out(cat_vars_for_one_hot)\n",
    "x_train_ohe = pd.DataFrame(x_train_ohe, columns=columns, index=x_train.index)\n",
    "\n",
    "# Repeat for validation/test data\n",
    "x_val_ohe = ohe_encoder.transform(x_val[cat_vars_for_one_hot])\n",
    "x_val_ohe = pd.DataFrame(x_val_ohe, columns=columns, index=x_val.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "a8d8b2bd-e661-4543-b730-25f476c5e4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add onehot encoded columns to x_train and x_val\n",
    "x_train = pd.concat([x_train.drop(columns=cat_vars_for_one_hot), x_train_ohe], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "ced8a9f1-3e2d-460a-8181-59bf2eac210a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = pd.concat([x_val.drop(columns=cat_vars_for_one_hot), x_val_ohe], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "b150e2e9-6400-406a-a1b3-165e029f40c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zip</th>\n",
       "      <th>NoEmp</th>\n",
       "      <th>FranchiseCode</th>\n",
       "      <th>UrbanRural</th>\n",
       "      <th>DisbursementGross</th>\n",
       "      <th>BalanceGross</th>\n",
       "      <th>HighRiskIndustry</th>\n",
       "      <th>LoanGrantRatio</th>\n",
       "      <th>PerEmployeeInvestment</th>\n",
       "      <th>NewBusiness</th>\n",
       "      <th>...</th>\n",
       "      <th>LoanSizeCategory_Micro</th>\n",
       "      <th>LoanSizeCategory_Small</th>\n",
       "      <th>LoanSizeCategory_Very Large</th>\n",
       "      <th>LoanSizeCategory_nan</th>\n",
       "      <th>JobCreationCategory_Few</th>\n",
       "      <th>JobCreationCategory_Many</th>\n",
       "      <th>JobCreationCategory_Massive</th>\n",
       "      <th>JobCreationCategory_Moderate</th>\n",
       "      <th>JobCreationCategory_None</th>\n",
       "      <th>JobCreationCategory_Some</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78577</th>\n",
       "      <td>-0.023060</td>\n",
       "      <td>-0.112077</td>\n",
       "      <td>-0.215919</td>\n",
       "      <td>0.374522</td>\n",
       "      <td>-0.526646</td>\n",
       "      <td>-0.00225</td>\n",
       "      <td>-0.285072</td>\n",
       "      <td>1.220495</td>\n",
       "      <td>-0.289298</td>\n",
       "      <td>-0.626342</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688865</th>\n",
       "      <td>0.051855</td>\n",
       "      <td>0.061364</td>\n",
       "      <td>-0.215919</td>\n",
       "      <td>0.374522</td>\n",
       "      <td>-0.051883</td>\n",
       "      <td>-0.00225</td>\n",
       "      <td>-0.285072</td>\n",
       "      <td>-0.425127</td>\n",
       "      <td>-0.314544</td>\n",
       "      <td>-0.626342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753608</th>\n",
       "      <td>-1.353901</td>\n",
       "      <td>-0.072052</td>\n",
       "      <td>-0.215997</td>\n",
       "      <td>0.374522</td>\n",
       "      <td>-0.474282</td>\n",
       "      <td>-0.00225</td>\n",
       "      <td>-0.285072</td>\n",
       "      <td>1.220495</td>\n",
       "      <td>-0.341356</td>\n",
       "      <td>-0.626342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538325</th>\n",
       "      <td>-0.429371</td>\n",
       "      <td>-0.138760</td>\n",
       "      <td>-0.215919</td>\n",
       "      <td>-1.172169</td>\n",
       "      <td>-0.552828</td>\n",
       "      <td>-0.00225</td>\n",
       "      <td>-0.285072</td>\n",
       "      <td>-0.630830</td>\n",
       "      <td>-0.147586</td>\n",
       "      <td>1.596573</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577652</th>\n",
       "      <td>0.827549</td>\n",
       "      <td>0.221462</td>\n",
       "      <td>-0.215919</td>\n",
       "      <td>-1.172169</td>\n",
       "      <td>1.567897</td>\n",
       "      <td>-0.00225</td>\n",
       "      <td>-0.285072</td>\n",
       "      <td>-0.425127</td>\n",
       "      <td>-0.128738</td>\n",
       "      <td>-0.626342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578687</th>\n",
       "      <td>0.989720</td>\n",
       "      <td>-0.138760</td>\n",
       "      <td>-0.215919</td>\n",
       "      <td>0.374522</td>\n",
       "      <td>-0.419126</td>\n",
       "      <td>-0.00225</td>\n",
       "      <td>-0.285072</td>\n",
       "      <td>-0.812332</td>\n",
       "      <td>0.162560</td>\n",
       "      <td>1.596573</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170150</th>\n",
       "      <td>0.352317</td>\n",
       "      <td>-0.138760</td>\n",
       "      <td>-0.215919</td>\n",
       "      <td>1.921212</td>\n",
       "      <td>-0.380028</td>\n",
       "      <td>-0.00225</td>\n",
       "      <td>-0.285072</td>\n",
       "      <td>-0.812332</td>\n",
       "      <td>0.253255</td>\n",
       "      <td>-0.626342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516750</th>\n",
       "      <td>-1.626057</td>\n",
       "      <td>-0.018686</td>\n",
       "      <td>-0.215919</td>\n",
       "      <td>0.374522</td>\n",
       "      <td>-0.195010</td>\n",
       "      <td>-0.00225</td>\n",
       "      <td>-0.285072</td>\n",
       "      <td>1.220495</td>\n",
       "      <td>-0.278256</td>\n",
       "      <td>-0.626342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115417</th>\n",
       "      <td>0.137605</td>\n",
       "      <td>-0.072052</td>\n",
       "      <td>-0.215919</td>\n",
       "      <td>0.374522</td>\n",
       "      <td>-0.376537</td>\n",
       "      <td>-0.00225</td>\n",
       "      <td>-0.285072</td>\n",
       "      <td>-0.812332</td>\n",
       "      <td>-0.276573</td>\n",
       "      <td>-0.626342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317121</th>\n",
       "      <td>-0.171383</td>\n",
       "      <td>-0.125419</td>\n",
       "      <td>-0.215919</td>\n",
       "      <td>-1.172169</td>\n",
       "      <td>-0.100755</td>\n",
       "      <td>-0.00225</td>\n",
       "      <td>-0.285072</td>\n",
       "      <td>-0.425127</td>\n",
       "      <td>0.436806</td>\n",
       "      <td>-0.626342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>720229 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Zip     NoEmp  FranchiseCode  UrbanRural  DisbursementGross  \\\n",
       "78577  -0.023060 -0.112077      -0.215919    0.374522          -0.526646   \n",
       "688865  0.051855  0.061364      -0.215919    0.374522          -0.051883   \n",
       "753608 -1.353901 -0.072052      -0.215997    0.374522          -0.474282   \n",
       "538325 -0.429371 -0.138760      -0.215919   -1.172169          -0.552828   \n",
       "577652  0.827549  0.221462      -0.215919   -1.172169           1.567897   \n",
       "...          ...       ...            ...         ...                ...   \n",
       "578687  0.989720 -0.138760      -0.215919    0.374522          -0.419126   \n",
       "170150  0.352317 -0.138760      -0.215919    1.921212          -0.380028   \n",
       "516750 -1.626057 -0.018686      -0.215919    0.374522          -0.195010   \n",
       "115417  0.137605 -0.072052      -0.215919    0.374522          -0.376537   \n",
       "317121 -0.171383 -0.125419      -0.215919   -1.172169          -0.100755   \n",
       "\n",
       "        BalanceGross  HighRiskIndustry  LoanGrantRatio  PerEmployeeInvestment  \\\n",
       "78577       -0.00225         -0.285072        1.220495              -0.289298   \n",
       "688865      -0.00225         -0.285072       -0.425127              -0.314544   \n",
       "753608      -0.00225         -0.285072        1.220495              -0.341356   \n",
       "538325      -0.00225         -0.285072       -0.630830              -0.147586   \n",
       "577652      -0.00225         -0.285072       -0.425127              -0.128738   \n",
       "...              ...               ...             ...                    ...   \n",
       "578687      -0.00225         -0.285072       -0.812332               0.162560   \n",
       "170150      -0.00225         -0.285072       -0.812332               0.253255   \n",
       "516750      -0.00225         -0.285072        1.220495              -0.278256   \n",
       "115417      -0.00225         -0.285072       -0.812332              -0.276573   \n",
       "317121      -0.00225         -0.285072       -0.425127               0.436806   \n",
       "\n",
       "        NewBusiness  ...  LoanSizeCategory_Micro  LoanSizeCategory_Small  \\\n",
       "78577     -0.626342  ...                     1.0                     0.0   \n",
       "688865    -0.626342  ...                     0.0                     0.0   \n",
       "753608    -0.626342  ...                     0.0                     1.0   \n",
       "538325     1.596573  ...                     1.0                     0.0   \n",
       "577652    -0.626342  ...                     0.0                     0.0   \n",
       "...             ...  ...                     ...                     ...   \n",
       "578687     1.596573  ...                     0.0                     1.0   \n",
       "170150    -0.626342  ...                     0.0                     1.0   \n",
       "516750    -0.626342  ...                     0.0                     1.0   \n",
       "115417    -0.626342  ...                     0.0                     1.0   \n",
       "317121    -0.626342  ...                     0.0                     0.0   \n",
       "\n",
       "        LoanSizeCategory_Very Large  LoanSizeCategory_nan  \\\n",
       "78577                           0.0                   0.0   \n",
       "688865                          0.0                   0.0   \n",
       "753608                          0.0                   0.0   \n",
       "538325                          0.0                   0.0   \n",
       "577652                          0.0                   0.0   \n",
       "...                             ...                   ...   \n",
       "578687                          0.0                   0.0   \n",
       "170150                          0.0                   0.0   \n",
       "516750                          0.0                   0.0   \n",
       "115417                          0.0                   0.0   \n",
       "317121                          0.0                   0.0   \n",
       "\n",
       "        JobCreationCategory_Few  JobCreationCategory_Many  \\\n",
       "78577                       1.0                       0.0   \n",
       "688865                      0.0                       0.0   \n",
       "753608                      0.0                       0.0   \n",
       "538325                      0.0                       0.0   \n",
       "577652                      0.0                       0.0   \n",
       "...                         ...                       ...   \n",
       "578687                      0.0                       0.0   \n",
       "170150                      0.0                       0.0   \n",
       "516750                      0.0                       0.0   \n",
       "115417                      0.0                       0.0   \n",
       "317121                      0.0                       0.0   \n",
       "\n",
       "        JobCreationCategory_Massive  JobCreationCategory_Moderate  \\\n",
       "78577                           0.0                           0.0   \n",
       "688865                          0.0                           1.0   \n",
       "753608                          0.0                           0.0   \n",
       "538325                          0.0                           0.0   \n",
       "577652                          0.0                           0.0   \n",
       "...                             ...                           ...   \n",
       "578687                          0.0                           0.0   \n",
       "170150                          0.0                           0.0   \n",
       "516750                          0.0                           0.0   \n",
       "115417                          0.0                           0.0   \n",
       "317121                          0.0                           0.0   \n",
       "\n",
       "        JobCreationCategory_None  JobCreationCategory_Some  \n",
       "78577                        0.0                       0.0  \n",
       "688865                       0.0                       0.0  \n",
       "753608                       0.0                       1.0  \n",
       "538325                       1.0                       0.0  \n",
       "577652                       1.0                       0.0  \n",
       "...                          ...                       ...  \n",
       "578687                       1.0                       0.0  \n",
       "170150                       1.0                       0.0  \n",
       "516750                       0.0                       1.0  \n",
       "115417                       1.0                       0.0  \n",
       "317121                       1.0                       0.0  \n",
       "\n",
       "[720229 rows x 31 columns]"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "89fdb9d6-2131-4538-a1ef-a1720bc943c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Assuming onehot_encoder is your fitted encoder\n",
    "with open('onehot_encoder.pkl', 'wb') as file:\n",
    "    pickle.dump(ohe_encoder, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "a68caca7-9223-4bad-b839-1b87d783042b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zip</th>\n",
       "      <th>NoEmp</th>\n",
       "      <th>FranchiseCode</th>\n",
       "      <th>UrbanRural</th>\n",
       "      <th>DisbursementGross</th>\n",
       "      <th>BalanceGross</th>\n",
       "      <th>HighRiskIndustry</th>\n",
       "      <th>LoanGrantRatio</th>\n",
       "      <th>PerEmployeeInvestment</th>\n",
       "      <th>NewBusiness</th>\n",
       "      <th>...</th>\n",
       "      <th>LoanSizeCategory_Micro</th>\n",
       "      <th>LoanSizeCategory_Small</th>\n",
       "      <th>LoanSizeCategory_Very Large</th>\n",
       "      <th>LoanSizeCategory_nan</th>\n",
       "      <th>JobCreationCategory_Few</th>\n",
       "      <th>JobCreationCategory_Many</th>\n",
       "      <th>JobCreationCategory_Massive</th>\n",
       "      <th>JobCreationCategory_Moderate</th>\n",
       "      <th>JobCreationCategory_None</th>\n",
       "      <th>JobCreationCategory_Some</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78577</th>\n",
       "      <td>-0.023060</td>\n",
       "      <td>-0.112077</td>\n",
       "      <td>-0.215919</td>\n",
       "      <td>0.374522</td>\n",
       "      <td>-0.526646</td>\n",
       "      <td>-0.00225</td>\n",
       "      <td>-0.285072</td>\n",
       "      <td>1.220495</td>\n",
       "      <td>-0.289298</td>\n",
       "      <td>-0.626342</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688865</th>\n",
       "      <td>0.051855</td>\n",
       "      <td>0.061364</td>\n",
       "      <td>-0.215919</td>\n",
       "      <td>0.374522</td>\n",
       "      <td>-0.051883</td>\n",
       "      <td>-0.00225</td>\n",
       "      <td>-0.285072</td>\n",
       "      <td>-0.425127</td>\n",
       "      <td>-0.314544</td>\n",
       "      <td>-0.626342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753608</th>\n",
       "      <td>-1.353901</td>\n",
       "      <td>-0.072052</td>\n",
       "      <td>-0.215997</td>\n",
       "      <td>0.374522</td>\n",
       "      <td>-0.474282</td>\n",
       "      <td>-0.00225</td>\n",
       "      <td>-0.285072</td>\n",
       "      <td>1.220495</td>\n",
       "      <td>-0.341356</td>\n",
       "      <td>-0.626342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538325</th>\n",
       "      <td>-0.429371</td>\n",
       "      <td>-0.138760</td>\n",
       "      <td>-0.215919</td>\n",
       "      <td>-1.172169</td>\n",
       "      <td>-0.552828</td>\n",
       "      <td>-0.00225</td>\n",
       "      <td>-0.285072</td>\n",
       "      <td>-0.630830</td>\n",
       "      <td>-0.147586</td>\n",
       "      <td>1.596573</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577652</th>\n",
       "      <td>0.827549</td>\n",
       "      <td>0.221462</td>\n",
       "      <td>-0.215919</td>\n",
       "      <td>-1.172169</td>\n",
       "      <td>1.567897</td>\n",
       "      <td>-0.00225</td>\n",
       "      <td>-0.285072</td>\n",
       "      <td>-0.425127</td>\n",
       "      <td>-0.128738</td>\n",
       "      <td>-0.626342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578687</th>\n",
       "      <td>0.989720</td>\n",
       "      <td>-0.138760</td>\n",
       "      <td>-0.215919</td>\n",
       "      <td>0.374522</td>\n",
       "      <td>-0.419126</td>\n",
       "      <td>-0.00225</td>\n",
       "      <td>-0.285072</td>\n",
       "      <td>-0.812332</td>\n",
       "      <td>0.162560</td>\n",
       "      <td>1.596573</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170150</th>\n",
       "      <td>0.352317</td>\n",
       "      <td>-0.138760</td>\n",
       "      <td>-0.215919</td>\n",
       "      <td>1.921212</td>\n",
       "      <td>-0.380028</td>\n",
       "      <td>-0.00225</td>\n",
       "      <td>-0.285072</td>\n",
       "      <td>-0.812332</td>\n",
       "      <td>0.253255</td>\n",
       "      <td>-0.626342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516750</th>\n",
       "      <td>-1.626057</td>\n",
       "      <td>-0.018686</td>\n",
       "      <td>-0.215919</td>\n",
       "      <td>0.374522</td>\n",
       "      <td>-0.195010</td>\n",
       "      <td>-0.00225</td>\n",
       "      <td>-0.285072</td>\n",
       "      <td>1.220495</td>\n",
       "      <td>-0.278256</td>\n",
       "      <td>-0.626342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115417</th>\n",
       "      <td>0.137605</td>\n",
       "      <td>-0.072052</td>\n",
       "      <td>-0.215919</td>\n",
       "      <td>0.374522</td>\n",
       "      <td>-0.376537</td>\n",
       "      <td>-0.00225</td>\n",
       "      <td>-0.285072</td>\n",
       "      <td>-0.812332</td>\n",
       "      <td>-0.276573</td>\n",
       "      <td>-0.626342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317121</th>\n",
       "      <td>-0.171383</td>\n",
       "      <td>-0.125419</td>\n",
       "      <td>-0.215919</td>\n",
       "      <td>-1.172169</td>\n",
       "      <td>-0.100755</td>\n",
       "      <td>-0.00225</td>\n",
       "      <td>-0.285072</td>\n",
       "      <td>-0.425127</td>\n",
       "      <td>0.436806</td>\n",
       "      <td>-0.626342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>720229 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Zip     NoEmp  FranchiseCode  UrbanRural  DisbursementGross  \\\n",
       "78577  -0.023060 -0.112077      -0.215919    0.374522          -0.526646   \n",
       "688865  0.051855  0.061364      -0.215919    0.374522          -0.051883   \n",
       "753608 -1.353901 -0.072052      -0.215997    0.374522          -0.474282   \n",
       "538325 -0.429371 -0.138760      -0.215919   -1.172169          -0.552828   \n",
       "577652  0.827549  0.221462      -0.215919   -1.172169           1.567897   \n",
       "...          ...       ...            ...         ...                ...   \n",
       "578687  0.989720 -0.138760      -0.215919    0.374522          -0.419126   \n",
       "170150  0.352317 -0.138760      -0.215919    1.921212          -0.380028   \n",
       "516750 -1.626057 -0.018686      -0.215919    0.374522          -0.195010   \n",
       "115417  0.137605 -0.072052      -0.215919    0.374522          -0.376537   \n",
       "317121 -0.171383 -0.125419      -0.215919   -1.172169          -0.100755   \n",
       "\n",
       "        BalanceGross  HighRiskIndustry  LoanGrantRatio  PerEmployeeInvestment  \\\n",
       "78577       -0.00225         -0.285072        1.220495              -0.289298   \n",
       "688865      -0.00225         -0.285072       -0.425127              -0.314544   \n",
       "753608      -0.00225         -0.285072        1.220495              -0.341356   \n",
       "538325      -0.00225         -0.285072       -0.630830              -0.147586   \n",
       "577652      -0.00225         -0.285072       -0.425127              -0.128738   \n",
       "...              ...               ...             ...                    ...   \n",
       "578687      -0.00225         -0.285072       -0.812332               0.162560   \n",
       "170150      -0.00225         -0.285072       -0.812332               0.253255   \n",
       "516750      -0.00225         -0.285072        1.220495              -0.278256   \n",
       "115417      -0.00225         -0.285072       -0.812332              -0.276573   \n",
       "317121      -0.00225         -0.285072       -0.425127               0.436806   \n",
       "\n",
       "        NewBusiness  ...  LoanSizeCategory_Micro  LoanSizeCategory_Small  \\\n",
       "78577     -0.626342  ...                     1.0                     0.0   \n",
       "688865    -0.626342  ...                     0.0                     0.0   \n",
       "753608    -0.626342  ...                     0.0                     1.0   \n",
       "538325     1.596573  ...                     1.0                     0.0   \n",
       "577652    -0.626342  ...                     0.0                     0.0   \n",
       "...             ...  ...                     ...                     ...   \n",
       "578687     1.596573  ...                     0.0                     1.0   \n",
       "170150    -0.626342  ...                     0.0                     1.0   \n",
       "516750    -0.626342  ...                     0.0                     1.0   \n",
       "115417    -0.626342  ...                     0.0                     1.0   \n",
       "317121    -0.626342  ...                     0.0                     0.0   \n",
       "\n",
       "        LoanSizeCategory_Very Large  LoanSizeCategory_nan  \\\n",
       "78577                           0.0                   0.0   \n",
       "688865                          0.0                   0.0   \n",
       "753608                          0.0                   0.0   \n",
       "538325                          0.0                   0.0   \n",
       "577652                          0.0                   0.0   \n",
       "...                             ...                   ...   \n",
       "578687                          0.0                   0.0   \n",
       "170150                          0.0                   0.0   \n",
       "516750                          0.0                   0.0   \n",
       "115417                          0.0                   0.0   \n",
       "317121                          0.0                   0.0   \n",
       "\n",
       "        JobCreationCategory_Few  JobCreationCategory_Many  \\\n",
       "78577                       1.0                       0.0   \n",
       "688865                      0.0                       0.0   \n",
       "753608                      0.0                       0.0   \n",
       "538325                      0.0                       0.0   \n",
       "577652                      0.0                       0.0   \n",
       "...                         ...                       ...   \n",
       "578687                      0.0                       0.0   \n",
       "170150                      0.0                       0.0   \n",
       "516750                      0.0                       0.0   \n",
       "115417                      0.0                       0.0   \n",
       "317121                      0.0                       0.0   \n",
       "\n",
       "        JobCreationCategory_Massive  JobCreationCategory_Moderate  \\\n",
       "78577                           0.0                           0.0   \n",
       "688865                          0.0                           1.0   \n",
       "753608                          0.0                           0.0   \n",
       "538325                          0.0                           0.0   \n",
       "577652                          0.0                           0.0   \n",
       "...                             ...                           ...   \n",
       "578687                          0.0                           0.0   \n",
       "170150                          0.0                           0.0   \n",
       "516750                          0.0                           0.0   \n",
       "115417                          0.0                           0.0   \n",
       "317121                          0.0                           0.0   \n",
       "\n",
       "        JobCreationCategory_None  JobCreationCategory_Some  \n",
       "78577                        0.0                       0.0  \n",
       "688865                       0.0                       0.0  \n",
       "753608                       0.0                       1.0  \n",
       "538325                       1.0                       0.0  \n",
       "577652                       1.0                       0.0  \n",
       "...                          ...                       ...  \n",
       "578687                       1.0                       0.0  \n",
       "170150                       1.0                       0.0  \n",
       "516750                       0.0                       1.0  \n",
       "115417                       1.0                       0.0  \n",
       "317121                       1.0                       0.0  \n",
       "\n",
       "[720229 rows x 31 columns]"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "ee142a30-025e-4f65-bcf6-1949a2d15c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MIS_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78577</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688865</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753608</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538325</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577652</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578687</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170150</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516750</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115417</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317121</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>720229 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        MIS_Status\n",
       "78577            0\n",
       "688865           1\n",
       "753608           1\n",
       "538325           0\n",
       "577652           0\n",
       "...            ...\n",
       "578687           0\n",
       "170150           0\n",
       "516750           0\n",
       "115417           0\n",
       "317121           0\n",
       "\n",
       "[720229 rows x 1 columns]"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c49f5a-0fe2-4d82-9235-590af6df47a4",
   "metadata": {},
   "source": [
    "# Model Training Step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b4966e-5a26-44c6-9b3e-9e43e67c5799",
   "metadata": {},
   "source": [
    "1) We run a dry model with random hyperparameters \n",
    "2) We compute the classification report for the corresponding model \n",
    "3) We analyze the metrics and identify where the tuning must be done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "cf5a28f7-535d-4735-a15f-ebb5bf769b54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_curve, auc,f1_score,classification_report,ConfusionMatrixDisplay,confusion_matrix\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "d8a3f8e9-07d2-4198-b331-413f8c215188",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.98      0.91     66046\n",
      "           1       0.58      0.15      0.24     13980\n",
      "\n",
      "    accuracy                           0.83     80026\n",
      "   macro avg       0.71      0.56      0.57     80026\n",
      "weighted avg       0.80      0.83      0.79     80026\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# First logreg model\n",
    "lr = LogisticRegression(C=0.01,penalty='l1', solver='saga', random_state=42, max_iter=500)\n",
    "lr.fit(x_train, y_t)\n",
    "y_pred = lr.predict(x_val)\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "00756e71-dbba-4259-ae7d-3928a64aef10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fa15e7689a0>"
      ]
     },
     "execution_count": 555,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_display = ConfusionMatrixDisplay(confusion_matrix = confusion_matrix(y_val, y_pred), display_labels = [False, True])\n",
    "cm_display.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "6186869e-75ba-4f1b-9138-a4ffcfa062d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculating ROC curve and AUC\n",
    "fpr, tpr, threshold = roc_curve(y_val, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plotting\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea11902-2e2d-4999-82c4-54f1a91d4625",
   "metadata": {},
   "source": [
    "# Model Tuning Step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44203f7c-7033-4f07-b5a3-ddbe7aa259c9",
   "metadata": {},
   "source": [
    "1) We first define the searchspace for our logrep model tuning\n",
    "2) We experiment with different regularizations and Max iterations\n",
    "3) After running GridSearch, we use different class weights to compare results\n",
    "4) We pick the best hyerparameters based on our tuning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "fd17da35-36c2-423a-8326-6a978d3b4ea9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 80 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "40 fits failed out of a total of 160.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1471, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.78319042 0.78330654        nan 0.7832778  0.78353077 0.78365697\n",
      "        nan 0.78362827 0.78360784 0.78376103        nan 0.78373999\n",
      " 0.78364924 0.7838102         nan 0.78379729 0.78366999 0.78384286\n",
      "        nan 0.78383998 0.78125135 0.78335479        nan 0.78327756\n",
      " 0.78129623 0.78361598        nan 0.78362844 0.78129624 0.78366465\n",
      "        nan 0.78374001 0.78129624 0.78367996        nan 0.78379724\n",
      " 0.78129624 0.78368018        nan 0.78383998 0.7832804  0.78328102\n",
      "        nan 0.78327704 0.78363284 0.78363265        nan 0.78362841\n",
      " 0.78373815 0.78374391        nan 0.78374005 0.78379336 0.78380024\n",
      "        nan 0.78379724 0.78383547 0.78384208        nan 0.78383998\n",
      " 0.78327817 0.78327816        nan 0.78327748 0.78362988 0.78362881\n",
      "        nan 0.78362823 0.78374055 0.78374045        nan 0.78374007\n",
      " 0.7837974  0.78379755        nan 0.78379726 0.7838401  0.78384023\n",
      "        nan 0.78383997]\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# We use GridSearch for hyperparameter tuning\n",
    "# we first define the searchspace for hyperparameters\n",
    "param_grid = [    \n",
    "    {'penalty' : ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'C' : [0.01,0.001,0.1,1],\n",
    "    'solver' : ['saga'],\n",
    "    'max_iter' : [100,300,500,700,1000]\n",
    "    }\n",
    "]\n",
    "# run the algorithm\n",
    "logModel = LogisticRegression()\n",
    "clf = GridSearchCV(logModel, param_grid = param_grid, cv = 2, verbose=True, n_jobs=-1,scoring='roc_auc')\n",
    "best_clf = clf.fit(x_train,y_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "c24252d7-4c75-4811-9a37-8601e7812db0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, max_iter=1000, solver='saga')"
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9d6ddefc-95b1-4573-ad07-633061f70376",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.84      0.91     76418\n",
      "           1       0.15      0.58      0.24      3608\n",
      "\n",
      "    accuracy                           0.83     80026\n",
      "   macro avg       0.56      0.71      0.57     80026\n",
      "weighted avg       0.94      0.83      0.88     80026\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# run the model with best parameters in gridsearch\n",
    "final_model=LogisticRegression(C= 0.01, penalty= 'none', solver= 'saga', max_iter=1000)\n",
    "final_model.fit(x_train, y_t)\n",
    "y_pred = final_model.predict(x_val)\n",
    "print(classification_report(y_pred,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a5cd7851-093a-4d00-bd60-e6b1d811c565",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {0: 1, 1: 1}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.98      0.91     66046\n",
      "           1       0.58      0.15      0.24     13980\n",
      "\n",
      "    accuracy                           0.83     80026\n",
      "   macro avg       0.71      0.56      0.57     80026\n",
      "weighted avg       0.80      0.83      0.79     80026\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {0: 1, 1: 2}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.90      0.89     66046\n",
      "           1       0.44      0.38      0.41     13980\n",
      "\n",
      "    accuracy                           0.81     80026\n",
      "   macro avg       0.66      0.64      0.65     80026\n",
      "weighted avg       0.80      0.81      0.80     80026\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {0: 1, 1: 2.05}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88     66046\n",
      "           1       0.44      0.39      0.41     13980\n",
      "\n",
      "    accuracy                           0.81     80026\n",
      "   macro avg       0.66      0.64      0.65     80026\n",
      "weighted avg       0.80      0.81      0.80     80026\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {0: 1, 1: 2.1}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88     66046\n",
      "           1       0.43      0.40      0.42     13980\n",
      "\n",
      "    accuracy                           0.80     80026\n",
      "   macro avg       0.65      0.64      0.65     80026\n",
      "weighted avg       0.80      0.80      0.80     80026\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {0: 1, 1: 2.3}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.87      0.88     66046\n",
      "           1       0.42      0.43      0.43     13980\n",
      "\n",
      "    accuracy                           0.80     80026\n",
      "   macro avg       0.65      0.65      0.65     80026\n",
      "weighted avg       0.80      0.80      0.80     80026\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {0: 1, 1: 2.35}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.87      0.87     66046\n",
      "           1       0.41      0.44      0.43     13980\n",
      "\n",
      "    accuracy                           0.79     80026\n",
      "   macro avg       0.65      0.66      0.65     80026\n",
      "weighted avg       0.80      0.79      0.80     80026\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {0: 1, 1: 2.7}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.84      0.86     66046\n",
      "           1       0.39      0.50      0.44     13980\n",
      "\n",
      "    accuracy                           0.78     80026\n",
      "   macro avg       0.64      0.67      0.65     80026\n",
      "weighted avg       0.80      0.78      0.79     80026\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {0: 1, 1: 2.9}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.82      0.85     66046\n",
      "           1       0.38      0.52      0.44     13980\n",
      "\n",
      "    accuracy                           0.77     80026\n",
      "   macro avg       0.64      0.67      0.65     80026\n",
      "weighted avg       0.80      0.77      0.78     80026\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {0: 1, 1: 3}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.81      0.85     66046\n",
      "           1       0.38      0.54      0.44     13980\n",
      "\n",
      "    accuracy                           0.76     80026\n",
      "   macro avg       0.63      0.67      0.65     80026\n",
      "weighted avg       0.80      0.76      0.78     80026\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {0: 1, 1: 4}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.73      0.81     66046\n",
      "           1       0.34      0.64      0.44     13980\n",
      "\n",
      "    accuracy                           0.72     80026\n",
      "   macro avg       0.62      0.69      0.63     80026\n",
      "weighted avg       0.81      0.72      0.75     80026\n",
      "\n",
      "Class weights: {0: 1, 1: 5}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.66      0.77     66046\n",
      "           1       0.31      0.72      0.43     13980\n",
      "\n",
      "    accuracy                           0.67     80026\n",
      "   macro avg       0.61      0.69      0.60     80026\n",
      "weighted avg       0.81      0.67      0.71     80026\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# now we try different classweights to find the best model for our project\n",
    "weights = [{0: 1, 1: w} for w in [1, 2,2.05,2.1,2.3,2.35,2.7,2.9,3,4,5]]\n",
    "for weight in weights:\n",
    "    lr = LogisticRegression(C=0.01,penalty='none', solver='saga', random_state=42, max_iter=1000,class_weight=weight)\n",
    "    lr.fit(x_train, y_t)\n",
    "    y_pred = lr.predict(x_val)\n",
    "    print(f\"Class weights: {weight}\")\n",
    "    print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54a28dd-af0a-4a39-a935-4a3339c9b00a",
   "metadata": {},
   "source": [
    "# Best Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898f0612-0097-46ec-8aff-4f2fde1323ac",
   "metadata": {},
   "source": [
    "1) We have identified the best model so we simply train the model\n",
    "2) We find the ideal threshold for our model\n",
    "3) We compute the metrics and export the model for scoring function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "5ee0f16e-e48b-4ba7-9c67-1fa6956ab1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.81      0.85     66046\n",
      "           1       0.38      0.54      0.44     13980\n",
      "\n",
      "    accuracy                           0.76     80026\n",
      "   macro avg       0.63      0.67      0.65     80026\n",
      "weighted avg       0.80      0.76      0.78     80026\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Fit the model with best hyperparameters\n",
    "bestlr = LogisticRegression(penalty='none', solver='saga', random_state=42, max_iter=1000,class_weight={0:1,1:3})\n",
    "bestlr.fit(x_train, y_t)\n",
    "y_pred = bestlr.predict(x_val)\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "f8d1085b-d702-4b49-947b-72eb661f845b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fa170ace5b0>"
      ]
     },
     "execution_count": 558,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_display = ConfusionMatrixDisplay(confusion_matrix = confusion_matrix(y_val, y_pred), display_labels = [False, True])\n",
    "cm_display.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "id": "0f2eadd5-1b43-4c73-9436-e699e633fbc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculating ROC curve and AUC\n",
    "fpr, tpr, threshold = roc_curve(y_val, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plotting\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "id": "ba846309-3c3d-4fc3-8e0a-8c1242fae347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Threshold using F1 Macro Score: 0.54\n"
     ]
    }
   ],
   "source": [
    "y_probs = bestlr.predict_proba(x_val)[:, 1]\n",
    "\n",
    "# Find optimal threshold using F1 macro score\n",
    "thresholds = np.arange(0, 1, 0.01)\n",
    "f1_scores = [f1_score(y_val, (y_probs > threshold).astype(int), average='macro') for threshold in thresholds]\n",
    "optimal_threshold = thresholds[np.argmax(f1_scores)]\n",
    "\n",
    "print(\"Optimal Threshold using F1 Macro Score:\", optimal_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "id": "a4dd33ab-9c57-436f-8c83-ea0e43bfe919",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('logistic_model.pkl', 'wb') as file:\n",
    "    pickle.dump(bestlr, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa774296-90ba-45e2-bed9-b736425f69cc",
   "metadata": {},
   "source": [
    "**Strategy for scoring:\n",
    "    Load artifacts one by one on this file and experiment on the validation file by loading it here first\n",
    "    Perform the trasformations and then the testing on the file and get the output the same way its done on the function\n",
    "    if it works , export the code from here to the scoring function.**\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06b2d37-d8ee-4200-93cd-78805f1abb31",
   "metadata": {},
   "source": [
    "**So the scoring function has been done. \n",
    "But there are some issues to address:\n",
    "    1) Data might be severely imbalanced since F1 score is low\n",
    "    2) Threshold is 0 which is bad again due to imbalance \n",
    "    3) Might have to drop original features in favor of engineered features or,\n",
    "    4) Feature Selection algorithms**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89a775e-3463-4d6f-abc9-ceec5a9a98e9",
   "metadata": {},
   "source": [
    "# H20 glm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2672c2ce-d159-4f14-9fdc-7a24160af671",
   "metadata": {},
   "source": [
    "1) Similar to sklearn we train a glm in h20 framework\n",
    "2) We repeat the same steps but we dont have to repeat the encoding steps since it has already been done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "id": "dba4a0c1-12ba-445e-920c-71e2f02fdf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h2o\n",
    "try:\n",
    "    h2o.cluster().shutdown()\n",
    "except:\n",
    "    pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "id": "3a691a78-8932-4b44-8589-bfb1dc02d436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-1.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-1 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-1 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-1 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table th,\n",
       "#h2o-table-1 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>1 day 15 hours 39 mins</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>America/Chicago</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.44.0.3</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>2 months and 28 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_srinathmurali_y7ymly</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>7.880 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.9.12 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  ------------------------------------\n",
       "H2O_cluster_uptime:         1 day 15 hours 39 mins\n",
       "H2O_cluster_timezone:       America/Chicago\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.44.0.3\n",
       "H2O_cluster_version_age:    2 months and 28 days\n",
       "H2O_cluster_name:           H2O_from_python_srinathmurali_y7ymly\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    7.880 Gb\n",
       "H2O_cluster_total_cores:    8\n",
       "H2O_cluster_allowed_cores:  8\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://localhost:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.9.12 final\n",
       "--------------------------  ------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Adjust as per limits on your PC\n",
    "# Limit to 8 threads and 8GB memory\n",
    "h2o.init(nthreads=8, max_mem_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "id": "6d2e3c72-f0a3-43c3-adbf-f37fa40d840d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming x_train is your data and y_train is your target column\n",
    "# Make sure y_train is a Series with the same index as x_train\n",
    "combined_df = pd.concat([x_train, y_t], axis=1)\n",
    "training_frame = h2o.H2OFrame(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "id": "ed03d771-02e7-48d0-bfa3-3cd04e4176ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "# validation frame\n",
    "combined_df_val = pd.concat([x_val, y_val], axis=1)\n",
    "validation_frame = h2o.H2OFrame(combined_df_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f46b699-8575-45f6-9c55-36f8fc67c920",
   "metadata": {},
   "source": [
    "# GLM Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9357bb11-3740-4d21-9e88-0ed650179b5f",
   "metadata": {},
   "source": [
    "We train the glm model with default set of hyperparamters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "id": "7b869d89-abce-4daf-9d10-a8bcb261b603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glm Model Build progress: |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/h2o/estimators/estimator_base.py:192: RuntimeWarning: We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n",
      "  warnings.warn(mesg[\"message\"], RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| (done) 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style='margin: 1em 0 1em 0;'>Model Details\n",
       "=============\n",
       "H2OGeneralizedLinearEstimator : Generalized Linear Modeling\n",
       "Model Key: GLM_model_python_1710821266515_115\n",
       "</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-2.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-2 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-2 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-2 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-2 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-2 .h2o-table th,\n",
       "#h2o-table-2 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-2 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-2\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>GLM Model: summary</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>family</th>\n",
       "<th>link</th>\n",
       "<th>regularization</th>\n",
       "<th>number_of_predictors_total</th>\n",
       "<th>number_of_active_predictors</th>\n",
       "<th>number_of_iterations</th>\n",
       "<th>training_frame</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>binomial</td>\n",
       "<td>logit</td>\n",
       "<td>Elastic Net (alpha = 0.5, lambda = 1.983E-4 )</td>\n",
       "<td>31</td>\n",
       "<td>28</td>\n",
       "<td>4</td>\n",
       "<td>Key_Frame__upload_a192a381ec49060d178efde966634972.hex</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomialGLM: glm\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.11992402103625602\n",
       "RMSE: 0.34630047796134505\n",
       "LogLoss: 0.38266771297091134\n",
       "AUC: 0.7839540166667974\n",
       "AUCPR: 0.4551022104752934\n",
       "Gini: 0.5679080333335949\n",
       "Null degrees of freedom: 720228\n",
       "Residual degrees of freedom: 720200\n",
       "Null deviance: 668474.1727504975\n",
       "Residual deviance: 551216.768490653\n",
       "AIC: 551274.768490653</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-3.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-3 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-3 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-3 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-3 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-3 .h2o-table th,\n",
       "#h2o-table-3 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-3 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-3\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.23909745269711485</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>0</th>\n",
       "<th>1</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>0</td>\n",
       "<td>475777.0</td>\n",
       "<td>118252.0</td>\n",
       "<td>0.1991</td>\n",
       "<td> (118252.0/594029.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>50746.0</td>\n",
       "<td>75454.0</td>\n",
       "<td>0.4021</td>\n",
       "<td> (50746.0/126200.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>526523.0</td>\n",
       "<td>193706.0</td>\n",
       "<td>0.2346</td>\n",
       "<td> (168998.0/720229.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-4.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-4 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-4 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-4 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-4 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-4 .h2o-table th,\n",
       "#h2o-table-4 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-4 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-4\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.2390975</td>\n",
       "<td>0.4717261</td>\n",
       "<td>219.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1318903</td>\n",
       "<td>0.6041237</td>\n",
       "<td>292.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.3711443</td>\n",
       "<td>0.4644071</td>\n",
       "<td>147.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.5131994</td>\n",
       "<td>0.8366436</td>\n",
       "<td>89.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9603034</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0023247</td>\n",
       "<td>1.0</td>\n",
       "<td>398.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9603034</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.2622470</td>\n",
       "<td>0.3426901</td>\n",
       "<td>205.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.1868499</td>\n",
       "<td>0.7097781</td>\n",
       "<td>252.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.1757722</td>\n",
       "<td>0.7106274</td>\n",
       "<td>260.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9603034</td>\n",
       "<td>594029.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9603034</td>\n",
       "<td>126181.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0012925</td>\n",
       "<td>594029.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0023247</td>\n",
       "<td>126200.0</td>\n",
       "<td>398.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9603034</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9603034</td>\n",
       "<td>0.9998494</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0012925</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0023247</td>\n",
       "<td>1.0</td>\n",
       "<td>398.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-5.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-5 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-5 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-5 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-5 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-5 .h2o-table th,\n",
       "#h2o-table-5 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-5 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-5\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 17.52 %, avg score: 17.52 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0100010</td>\n",
       "<td>0.6878465</td>\n",
       "<td>4.4076479</td>\n",
       "<td>4.4076479</td>\n",
       "<td>0.7723171</td>\n",
       "<td>0.7557351</td>\n",
       "<td>0.7723171</td>\n",
       "<td>0.7557351</td>\n",
       "<td>0.0440808</td>\n",
       "<td>0.0440808</td>\n",
       "<td>340.7647904</td>\n",
       "<td>340.7647904</td>\n",
       "<td>0.0413200</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0200006</td>\n",
       "<td>0.6200657</td>\n",
       "<td>3.7933382</td>\n",
       "<td>4.1005144</td>\n",
       "<td>0.6646765</td>\n",
       "<td>0.6523455</td>\n",
       "<td>0.7185005</td>\n",
       "<td>0.7040439</td>\n",
       "<td>0.0379319</td>\n",
       "<td>0.0820127</td>\n",
       "<td>279.3338159</td>\n",
       "<td>310.0514354</td>\n",
       "<td>0.0751864</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0300002</td>\n",
       "<td>0.5679251</td>\n",
       "<td>3.3844469</td>\n",
       "<td>3.8618362</td>\n",
       "<td>0.5930297</td>\n",
       "<td>0.5930573</td>\n",
       "<td>0.6766789</td>\n",
       "<td>0.6670501</td>\n",
       "<td>0.0338431</td>\n",
       "<td>0.1158558</td>\n",
       "<td>238.4446893</td>\n",
       "<td>286.1836247</td>\n",
       "<td>0.1040954</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0400012</td>\n",
       "<td>0.5268817</td>\n",
       "<td>3.1415287</td>\n",
       "<td>3.6817468</td>\n",
       "<td>0.5504651</td>\n",
       "<td>0.5468343</td>\n",
       "<td>0.6451232</td>\n",
       "<td>0.6369940</td>\n",
       "<td>0.0314184</td>\n",
       "<td>0.1472742</td>\n",
       "<td>214.1528661</td>\n",
       "<td>268.1746850</td>\n",
       "<td>0.1300629</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0500008</td>\n",
       "<td>0.4907251</td>\n",
       "<td>2.8820495</td>\n",
       "<td>3.5218163</td>\n",
       "<td>0.5049986</td>\n",
       "<td>0.5081666</td>\n",
       "<td>0.6170999</td>\n",
       "<td>0.6112300</td>\n",
       "<td>0.0288193</td>\n",
       "<td>0.1760935</td>\n",
       "<td>188.2049485</td>\n",
       "<td>252.1816259</td>\n",
       "<td>0.1528808</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1000001</td>\n",
       "<td>0.3962578</td>\n",
       "<td>2.5320443</td>\n",
       "<td>3.0269372</td>\n",
       "<td>0.4436700</td>\n",
       "<td>0.4372308</td>\n",
       "<td>0.5303861</td>\n",
       "<td>0.5242316</td>\n",
       "<td>0.1266006</td>\n",
       "<td>0.3026941</td>\n",
       "<td>153.2044319</td>\n",
       "<td>202.6937160</td>\n",
       "<td>0.2457558</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1500009</td>\n",
       "<td>0.3365752</td>\n",
       "<td>2.0803169</td>\n",
       "<td>2.7113941</td>\n",
       "<td>0.3645174</td>\n",
       "<td>0.3645426</td>\n",
       "<td>0.4750960</td>\n",
       "<td>0.4710014</td>\n",
       "<td>0.1040174</td>\n",
       "<td>0.4067116</td>\n",
       "<td>108.0316880</td>\n",
       "<td>171.1394146</td>\n",
       "<td>0.3112482</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2000003</td>\n",
       "<td>0.2903421</td>\n",
       "<td>1.7689603</td>\n",
       "<td>2.4757890</td>\n",
       "<td>0.3099608</td>\n",
       "<td>0.3128540</td>\n",
       "<td>0.4338128</td>\n",
       "<td>0.4314651</td>\n",
       "<td>0.0884469</td>\n",
       "<td>0.4951585</td>\n",
       "<td>76.8960298</td>\n",
       "<td>147.5788956</td>\n",
       "<td>0.3578638</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.3000004</td>\n",
       "<td>0.2189490</td>\n",
       "<td>1.4247207</td>\n",
       "<td>2.1254329</td>\n",
       "<td>0.2496425</td>\n",
       "<td>0.2525257</td>\n",
       "<td>0.3724227</td>\n",
       "<td>0.3718186</td>\n",
       "<td>0.1424723</td>\n",
       "<td>0.6376307</td>\n",
       "<td>42.4720684</td>\n",
       "<td>112.5432865</td>\n",
       "<td>0.4093591</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.4000006</td>\n",
       "<td>0.1688380</td>\n",
       "<td>1.0899351</td>\n",
       "<td>1.8665584</td>\n",
       "<td>0.1909807</td>\n",
       "<td>0.1928112</td>\n",
       "<td>0.3270622</td>\n",
       "<td>0.3270668</td>\n",
       "<td>0.1089937</td>\n",
       "<td>0.7466244</td>\n",
       "<td>8.9935095</td>\n",
       "<td>86.6558423</td>\n",
       "<td>0.4202632</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5000007</td>\n",
       "<td>0.1280731</td>\n",
       "<td>0.8108547</td>\n",
       "<td>1.6554177</td>\n",
       "<td>0.1420796</td>\n",
       "<td>0.1477886</td>\n",
       "<td>0.2900657</td>\n",
       "<td>0.2912111</td>\n",
       "<td>0.0810856</td>\n",
       "<td>0.8277100</td>\n",
       "<td>-18.9145341</td>\n",
       "<td>65.5417670</td>\n",
       "<td>0.3973303</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.5999994</td>\n",
       "<td>0.0954515</td>\n",
       "<td>0.6140330</td>\n",
       "<td>1.4818556</td>\n",
       "<td>0.1075921</td>\n",
       "<td>0.1111834</td>\n",
       "<td>0.2596538</td>\n",
       "<td>0.2612069</td>\n",
       "<td>0.0614025</td>\n",
       "<td>0.8891125</td>\n",
       "<td>-38.5966970</td>\n",
       "<td>48.1855571</td>\n",
       "<td>0.3505344</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.6999996</td>\n",
       "<td>0.0693389</td>\n",
       "<td>0.4772577</td>\n",
       "<td>1.3383413</td>\n",
       "<td>0.0836261</td>\n",
       "<td>0.0818925</td>\n",
       "<td>0.2345069</td>\n",
       "<td>0.2355905</td>\n",
       "<td>0.0477258</td>\n",
       "<td>0.9368384</td>\n",
       "<td>-52.2742343</td>\n",
       "<td>33.8341299</td>\n",
       "<td>0.2871546</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.7999997</td>\n",
       "<td>0.0476020</td>\n",
       "<td>0.3554670</td>\n",
       "<td>1.2154818</td>\n",
       "<td>0.0622857</td>\n",
       "<td>0.0582599</td>\n",
       "<td>0.2129792</td>\n",
       "<td>0.2134241</td>\n",
       "<td>0.0355468</td>\n",
       "<td>0.9723851</td>\n",
       "<td>-64.4532982</td>\n",
       "<td>21.5481801</td>\n",
       "<td>0.2090082</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8999999</td>\n",
       "<td>0.0233880</td>\n",
       "<td>0.2416795</td>\n",
       "<td>1.1072814</td>\n",
       "<td>0.0423476</td>\n",
       "<td>0.0363106</td>\n",
       "<td>0.1940201</td>\n",
       "<td>0.1937448</td>\n",
       "<td>0.0241680</td>\n",
       "<td>0.9965531</td>\n",
       "<td>-75.8320462</td>\n",
       "<td>10.7281382</td>\n",
       "<td>0.1170657</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000041</td>\n",
       "<td>0.0344690</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0060397</td>\n",
       "<td>0.0086487</td>\n",
       "<td>0.1752220</td>\n",
       "<td>0.1752352</td>\n",
       "<td>0.0034469</td>\n",
       "<td>1.0</td>\n",
       "<td>-96.5530951</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-6.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-6 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-6 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-6 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-6 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-6 .h2o-table th,\n",
       "#h2o-table-6 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-6 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-6\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Scoring History: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>timestamp</th>\n",
       "<th>duration</th>\n",
       "<th>iterations</th>\n",
       "<th>negative_log_likelihood</th>\n",
       "<th>objective</th>\n",
       "<th>training_rmse</th>\n",
       "<th>training_logloss</th>\n",
       "<th>training_r2</th>\n",
       "<th>training_auc</th>\n",
       "<th>training_pr_auc</th>\n",
       "<th>training_lift</th>\n",
       "<th>training_classification_error</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>2024-03-20 14:48:10</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>0</td>\n",
       "<td>334237.0863752</td>\n",
       "<td>0.4640706</td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2024-03-20 14:48:10</td>\n",
       "<td> 0.235 sec</td>\n",
       "<td>1</td>\n",
       "<td>284206.8436929</td>\n",
       "<td>0.3949257</td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2024-03-20 14:48:10</td>\n",
       "<td> 0.352 sec</td>\n",
       "<td>2</td>\n",
       "<td>276542.1175382</td>\n",
       "<td>0.3843469</td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2024-03-20 14:48:10</td>\n",
       "<td> 0.465 sec</td>\n",
       "<td>3</td>\n",
       "<td>275632.7662830</td>\n",
       "<td>0.3831254</td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2024-03-20 14:48:10</td>\n",
       "<td> 0.570 sec</td>\n",
       "<td>4</td>\n",
       "<td>275608.3842453</td>\n",
       "<td>0.3830974</td>\n",
       "<td>0.3463005</td>\n",
       "<td>0.3826677</td>\n",
       "<td>0.1701867</td>\n",
       "<td>0.7839540</td>\n",
       "<td>0.4551022</td>\n",
       "<td>4.4076479</td>\n",
       "<td>0.2346448</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-7.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-7 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-7 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-7 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-7 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-7 .h2o-table th,\n",
       "#h2o-table-7 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-7 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-7\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Variable Importances: </caption>\n",
       "    <thead><tr><th>variable</th>\n",
       "<th>relative_importance</th>\n",
       "<th>scaled_importance</th>\n",
       "<th>percentage</th></tr></thead>\n",
       "    <tbody><tr><td>Bank_woe</td>\n",
       "<td>1.0917900</td>\n",
       "<td>1.0</td>\n",
       "<td>0.3112304</td></tr>\n",
       "<tr><td>City_woe</td>\n",
       "<td>0.4261594</td>\n",
       "<td>0.3903309</td>\n",
       "<td>0.1214828</td></tr>\n",
       "<tr><td>UrbanRural</td>\n",
       "<td>0.2725182</td>\n",
       "<td>0.2496068</td>\n",
       "<td>0.0776852</td></tr>\n",
       "<tr><td>LoanSizeCategory_Micro</td>\n",
       "<td>0.2360448</td>\n",
       "<td>0.2161998</td>\n",
       "<td>0.0672880</td></tr>\n",
       "<tr><td>UrbanBusiness</td>\n",
       "<td>0.1960278</td>\n",
       "<td>0.1795471</td>\n",
       "<td>0.0558805</td></tr>\n",
       "<tr><td>LoanSizeCategory_Small</td>\n",
       "<td>0.1658982</td>\n",
       "<td>0.1519507</td>\n",
       "<td>0.0472917</td></tr>\n",
       "<tr><td>LowDoc_Y</td>\n",
       "<td>0.1234942</td>\n",
       "<td>0.1131117</td>\n",
       "<td>0.0352038</td></tr>\n",
       "<tr><td>EconomicSector</td>\n",
       "<td>0.1048872</td>\n",
       "<td>0.0960690</td>\n",
       "<td>0.0298996</td></tr>\n",
       "<tr><td>LoanGrantRatio</td>\n",
       "<td>0.1007042</td>\n",
       "<td>0.0922377</td>\n",
       "<td>0.0287072</td></tr>\n",
       "<tr><td>JobCreationCategory_Few</td>\n",
       "<td>0.0881260</td>\n",
       "<td>0.0807170</td>\n",
       "<td>0.0251216</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>LoanSizeCategory_Very Large</td>\n",
       "<td>0.0255863</td>\n",
       "<td>0.0234352</td>\n",
       "<td>0.0072937</td></tr>\n",
       "<tr><td>State_woe</td>\n",
       "<td>0.0221664</td>\n",
       "<td>0.0203028</td>\n",
       "<td>0.0063189</td></tr>\n",
       "<tr><td>JobCreationCategory_Massive</td>\n",
       "<td>0.0177220</td>\n",
       "<td>0.0162321</td>\n",
       "<td>0.0050519</td></tr>\n",
       "<tr><td>NoEmp</td>\n",
       "<td>0.0168360</td>\n",
       "<td>0.0154205</td>\n",
       "<td>0.0047993</td></tr>\n",
       "<tr><td>ExpansionPlan</td>\n",
       "<td>0.0065392</td>\n",
       "<td>0.0059895</td>\n",
       "<td>0.0018641</td></tr>\n",
       "<tr><td>BalanceGross</td>\n",
       "<td>0.0038743</td>\n",
       "<td>0.0035486</td>\n",
       "<td>0.0011044</td></tr>\n",
       "<tr><td>JobCreationCategory_Many</td>\n",
       "<td>0.0035669</td>\n",
       "<td>0.0032670</td>\n",
       "<td>0.0010168</td></tr>\n",
       "<tr><td>PerEmployeeInvestment</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>LoanSizeCategory_nan</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>JobCreationCategory_None</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "<pre style='font-size: smaller; margin-bottom: 1em;'>[31 rows x 4 columns]</pre></div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
      ],
      "text/plain": [
       "Model Details\n",
       "=============\n",
       "H2OGeneralizedLinearEstimator : Generalized Linear Modeling\n",
       "Model Key: GLM_model_python_1710821266515_115\n",
       "\n",
       "\n",
       "GLM Model: summary\n",
       "    family    link    regularization                                 number_of_predictors_total    number_of_active_predictors    number_of_iterations    training_frame\n",
       "--  --------  ------  ---------------------------------------------  ----------------------------  -----------------------------  ----------------------  ------------------------------------------------------\n",
       "    binomial  logit   Elastic Net (alpha = 0.5, lambda = 1.983E-4 )  31                            28                             4                       Key_Frame__upload_a192a381ec49060d178efde966634972.hex\n",
       "\n",
       "ModelMetricsBinomialGLM: glm\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.11992402103625602\n",
       "RMSE: 0.34630047796134505\n",
       "LogLoss: 0.38266771297091134\n",
       "AUC: 0.7839540166667974\n",
       "AUCPR: 0.4551022104752934\n",
       "Gini: 0.5679080333335949\n",
       "Null degrees of freedom: 720228\n",
       "Residual degrees of freedom: 720200\n",
       "Null deviance: 668474.1727504975\n",
       "Residual deviance: 551216.768490653\n",
       "AIC: 551274.768490653\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.23909745269711485\n",
       "       0       1       Error    Rate\n",
       "-----  ------  ------  -------  -------------------\n",
       "0      475777  118252  0.1991   (118252.0/594029.0)\n",
       "1      50746   75454   0.4021   (50746.0/126200.0)\n",
       "Total  526523  193706  0.2346   (168998.0/720229.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.239097     0.471726  219\n",
       "max f2                       0.13189      0.604124  292\n",
       "max f0point5                 0.371144     0.464407  147\n",
       "max accuracy                 0.513199     0.836644  89\n",
       "max precision                0.960303     1         0\n",
       "max recall                   0.00232468   1         398\n",
       "max specificity              0.960303     1         0\n",
       "max absolute_mcc             0.262247     0.34269   205\n",
       "max min_per_class_accuracy   0.18685      0.709778  252\n",
       "max mean_per_class_accuracy  0.175772     0.710627  260\n",
       "max tns                      0.960303     594029    0\n",
       "max fns                      0.960303     126181    0\n",
       "max fps                      0.00129246   594029    399\n",
       "max tps                      0.00232468   126200    398\n",
       "max tnr                      0.960303     1         0\n",
       "max fnr                      0.960303     0.999849  0\n",
       "max fpr                      0.00129246   1         399\n",
       "max tpr                      0.00232468   1         398\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 17.52 %, avg score: 17.52 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  --------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.010001                    0.687847           4.40765   4.40765            0.772317         0.755735    0.772317                    0.755735            0.0440808       0.0440808                  340.765   340.765            0.04132\n",
       "2        0.0200006                   0.620066           3.79334   4.10051            0.664676         0.652345    0.718501                    0.704044            0.0379319       0.0820127                  279.334   310.051            0.0751864\n",
       "3        0.0300002                   0.567925           3.38445   3.86184            0.59303          0.593057    0.676679                    0.66705             0.0338431       0.115856                   238.445   286.184            0.104095\n",
       "4        0.0400012                   0.526882           3.14153   3.68175            0.550465         0.546834    0.645123                    0.636994            0.0314184       0.147274                   214.153   268.175            0.130063\n",
       "5        0.0500008                   0.490725           2.88205   3.52182            0.504999         0.508167    0.6171                      0.61123             0.0288193       0.176094                   188.205   252.182            0.152881\n",
       "6        0.1                         0.396258           2.53204   3.02694            0.44367          0.437231    0.530386                    0.524232            0.126601        0.302694                   153.204   202.694            0.245756\n",
       "7        0.150001                    0.336575           2.08032   2.71139            0.364517         0.364543    0.475096                    0.471001            0.104017        0.406712                   108.032   171.139            0.311248\n",
       "8        0.2                         0.290342           1.76896   2.47579            0.309961         0.312854    0.433813                    0.431465            0.0884469       0.495158                   76.896    147.579            0.357864\n",
       "9        0.3                         0.218949           1.42472   2.12543            0.249642         0.252526    0.372423                    0.371819            0.142472        0.637631                   42.4721   112.543            0.409359\n",
       "10       0.400001                    0.168838           1.08994   1.86656            0.190981         0.192811    0.327062                    0.327067            0.108994        0.746624                   8.99351   86.6558            0.420263\n",
       "11       0.500001                    0.128073           0.810855  1.65542            0.14208          0.147789    0.290066                    0.291211            0.0810856       0.82771                    -18.9145  65.5418            0.39733\n",
       "12       0.599999                    0.0954515          0.614033  1.48186            0.107592         0.111183    0.259654                    0.261207            0.0614025       0.889113                   -38.5967  48.1856            0.350534\n",
       "13       0.7                         0.0693389          0.477258  1.33834            0.0836261        0.0818925   0.234507                    0.23559             0.0477258       0.936838                   -52.2742  33.8341            0.287155\n",
       "14       0.8                         0.047602           0.355467  1.21548            0.0622857        0.0582599   0.212979                    0.213424            0.0355468       0.972385                   -64.4533  21.5482            0.209008\n",
       "15       0.9                         0.023388           0.24168   1.10728            0.0423476        0.0363106   0.19402                     0.193745            0.024168        0.996553                   -75.832   10.7281            0.117066\n",
       "16       1                           4.13604e-06        0.034469  1                  0.00603974       0.00864874  0.175222                    0.175235            0.00344691      1                          -96.5531  0                  0\n",
       "\n",
       "Scoring History: \n",
       "    timestamp            duration    iterations    negative_log_likelihood    objective    training_rmse        training_logloss     training_r2          training_auc        training_pr_auc     training_lift      training_classification_error\n",
       "--  -------------------  ----------  ------------  -------------------------  -----------  -------------------  -------------------  -------------------  ------------------  ------------------  -----------------  -------------------------------\n",
       "    2024-03-20 14:48:10  0.000 sec   0             334237                     0.464071\n",
       "    2024-03-20 14:48:10  0.235 sec   1             284207                     0.394926\n",
       "    2024-03-20 14:48:10  0.352 sec   2             276542                     0.384347\n",
       "    2024-03-20 14:48:10  0.465 sec   3             275633                     0.383125\n",
       "    2024-03-20 14:48:10  0.570 sec   4             275608                     0.383097     0.34630047796134505  0.38266771297091134  0.17018670609136044  0.7839540166667974  0.4551022104752934  4.407647904014285  0.2346448143576557\n",
       "\n",
       "Variable Importances: \n",
       "variable                     relative_importance    scaled_importance     percentage\n",
       "---------------------------  ---------------------  --------------------  ---------------------\n",
       "Bank_woe                     1.091789960861206      1.0                   0.3112303531778345\n",
       "City_woe                     0.42615941166877747    0.39033094912561944   0.12148283915260588\n",
       "UrbanRural                   0.2725181579589844     0.24960676295651366   0.07768520099053175\n",
       "LoanSizeCategory_Micro       0.23604480922222137    0.21619983484371735   0.06728795095539963\n",
       "UrbanBusiness                0.19602777063846588    0.17954714520715945   0.05588052141489616\n",
       "LoanSizeCategory_Small       0.16589821875095367    0.151950672471922     0.04729166145904574\n",
       "LowDoc_Y                     0.1234942078590393     0.11311169023905188   0.035203791301641925\n",
       "EconomicSector               0.10488715767860413    0.09606898894350424   0.029899585358324297\n",
       "LoanGrantRatio               0.10070423781871796    0.09223773933521266   0.028707184189623272\n",
       "JobCreationCategory_Few      0.08812598884105682    0.08071698037188661   0.025121574308590605\n",
       "---                          ---                    ---                   ---\n",
       "LoanSizeCategory_Very Large  0.025586329400539398   0.023435212190774178  0.00729374936693214\n",
       "State_woe                    0.02216644398868084    0.02030284650281626   0.006318862087586866\n",
       "JobCreationCategory_Massive  0.017722006887197495   0.016232066168861217  0.005051911686540655\n",
       "NoEmp                        0.016835996881127357   0.015420545603704847  0.0047993418544359625\n",
       "ExpansionPlan                0.0065392362885177135  0.005989463654125882  0.0018641028884194015\n",
       "BalanceGross                 0.00387428211979568    0.003548559941638993  0.0011044195639090195\n",
       "JobCreationCategory_Many     0.0035668881610035896  0.003267009487969665  0.001016792516776135\n",
       "PerEmployeeInvestment        0.0                    0.0                   0.0\n",
       "LoanSizeCategory_nan         0.0                    0.0                   0.0\n",
       "JobCreationCategory_None     0.0                    0.0                   0.0\n",
       "[31 rows x 4 columns]\n",
       "\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section."
      ]
     },
     "execution_count": 568,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from h2o.estimators import H2OGeneralizedLinearEstimator\n",
    "\n",
    "# Specify the feature and target names\n",
    "feature_cols = x_train.columns.tolist()\n",
    "target_col = 'MIS_Status'\n",
    "\n",
    "# Define and train the model\n",
    "model = H2OGeneralizedLinearEstimator(family=\"binomial\")  # Example for logistic regression\n",
    "model.train(x=feature_cols, y=target_col, training_frame=training_frame)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfbcfc1-8300-4c2b-ab1b-6140b76f36d6",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7852ab5-c578-495a-96bd-454465ed0f9a",
   "metadata": {},
   "source": [
    "1) We use gridsearch to find ideal set of hyperparameters\n",
    "2) We extract the best model directly from gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "90599611-464d-4eab-bf40-32282d3fccf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glm Grid Build progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| (done) 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/h2o/grid/grid_search.py:429: UserWarning: Adding alpha array to hyperparameter runs slower with gridsearch. This is due to the fact that the algo has to run initialization for every alpha value. Setting the alpha array as a model parameter will skip the initialization and run faster overall.\n",
      "  warnings.warn(w_message)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-8.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-8 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-8 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-8 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-8 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-8 .h2o-table th,\n",
       "#h2o-table-8 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-8 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-8\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Hyper-Parameter Search Summary: ordered by increasing logloss</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>alpha</th>\n",
       "<th>lambda</th>\n",
       "<th>model_ids</th>\n",
       "<th>logloss</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>0.4</td>\n",
       "<td>0.001</td>\n",
       "<td>Grid_GLM_Key_Frame__upload_a192a381ec49060d178efde966634972.hex_model_python_1710821266515_117_model_15</td>\n",
       "<td>0.3966759</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.6</td>\n",
       "<td>0.001</td>\n",
       "<td>Grid_GLM_Key_Frame__upload_a192a381ec49060d178efde966634972.hex_model_python_1710821266515_117_model_16</td>\n",
       "<td>0.3966837</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.2</td>\n",
       "<td>0.001</td>\n",
       "<td>Grid_GLM_Key_Frame__upload_a192a381ec49060d178efde966634972.hex_model_python_1710821266515_117_model_14</td>\n",
       "<td>0.3966879</td></tr>\n",
       "<tr><td></td>\n",
       "<td>1.0</td>\n",
       "<td>0.001</td>\n",
       "<td>Grid_GLM_Key_Frame__upload_a192a381ec49060d178efde966634972.hex_model_python_1710821266515_117_model_18</td>\n",
       "<td>0.3966898</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.8</td>\n",
       "<td>0.001</td>\n",
       "<td>Grid_GLM_Key_Frame__upload_a192a381ec49060d178efde966634972.hex_model_python_1710821266515_117_model_17</td>\n",
       "<td>0.3966904</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.0</td>\n",
       "<td>0.001</td>\n",
       "<td>Grid_GLM_Key_Frame__upload_a192a381ec49060d178efde966634972.hex_model_python_1710821266515_117_model_13</td>\n",
       "<td>0.3967103</td></tr>\n",
       "<tr><td></td>\n",
       "<td>1.0</td>\n",
       "<td>0.0001</td>\n",
       "<td>Grid_GLM_Key_Frame__upload_a192a381ec49060d178efde966634972.hex_model_python_1710821266515_117_model_12</td>\n",
       "<td>0.3968081</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.8</td>\n",
       "<td>0.0001</td>\n",
       "<td>Grid_GLM_Key_Frame__upload_a192a381ec49060d178efde966634972.hex_model_python_1710821266515_117_model_11</td>\n",
       "<td>0.3968123</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.6</td>\n",
       "<td>0.0001</td>\n",
       "<td>Grid_GLM_Key_Frame__upload_a192a381ec49060d178efde966634972.hex_model_python_1710821266515_117_model_10</td>\n",
       "<td>0.3968141</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.4</td>\n",
       "<td>0.0001</td>\n",
       "<td>Grid_GLM_Key_Frame__upload_a192a381ec49060d178efde966634972.hex_model_python_1710821266515_117_model_9</td>\n",
       "<td>0.3968164</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td></td>\n",
       "<td>1.0</td>\n",
       "<td>0.3</td>\n",
       "<td>Grid_GLM_Key_Frame__upload_a192a381ec49060d178efde966634972.hex_model_python_1710821266515_117_model_42</td>\n",
       "<td>0.4632514</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.4</td>\n",
       "<td>0.4</td>\n",
       "<td>Grid_GLM_Key_Frame__upload_a192a381ec49060d178efde966634972.hex_model_python_1710821266515_117_model_45</td>\n",
       "<td>0.4632514</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.6</td>\n",
       "<td>0.4</td>\n",
       "<td>Grid_GLM_Key_Frame__upload_a192a381ec49060d178efde966634972.hex_model_python_1710821266515_117_model_46</td>\n",
       "<td>0.4632514</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.8</td>\n",
       "<td>0.4</td>\n",
       "<td>Grid_GLM_Key_Frame__upload_a192a381ec49060d178efde966634972.hex_model_python_1710821266515_117_model_47</td>\n",
       "<td>0.4632514</td></tr>\n",
       "<tr><td></td>\n",
       "<td>1.0</td>\n",
       "<td>0.4</td>\n",
       "<td>Grid_GLM_Key_Frame__upload_a192a381ec49060d178efde966634972.hex_model_python_1710821266515_117_model_48</td>\n",
       "<td>0.4632514</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.2</td>\n",
       "<td>0.5</td>\n",
       "<td>Grid_GLM_Key_Frame__upload_a192a381ec49060d178efde966634972.hex_model_python_1710821266515_117_model_50</td>\n",
       "<td>0.4632514</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.4</td>\n",
       "<td>0.5</td>\n",
       "<td>Grid_GLM_Key_Frame__upload_a192a381ec49060d178efde966634972.hex_model_python_1710821266515_117_model_51</td>\n",
       "<td>0.4632514</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.6</td>\n",
       "<td>0.5</td>\n",
       "<td>Grid_GLM_Key_Frame__upload_a192a381ec49060d178efde966634972.hex_model_python_1710821266515_117_model_52</td>\n",
       "<td>0.4632514</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.8</td>\n",
       "<td>0.5</td>\n",
       "<td>Grid_GLM_Key_Frame__upload_a192a381ec49060d178efde966634972.hex_model_python_1710821266515_117_model_53</td>\n",
       "<td>0.4632514</td></tr>\n",
       "<tr><td></td>\n",
       "<td>1.0</td>\n",
       "<td>0.5</td>\n",
       "<td>Grid_GLM_Key_Frame__upload_a192a381ec49060d178efde966634972.hex_model_python_1710821266515_117_model_54</td>\n",
       "<td>0.4632514</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "<pre style='font-size: smaller; margin-bottom: 1em;'>[54 rows x 5 columns]</pre>"
      ],
      "text/plain": [
       "Hyper-Parameter Search Summary: ordered by increasing logloss\n",
       "     alpha    lambda    model_ids                                                                                                logloss\n",
       "---  -------  --------  -------------------------------------------------------------------------------------------------------  -------------------\n",
       "     0.4      0.001     Grid_GLM_Key_Frame__upload_a192a381ec49060d178efde966634972.hex_model_python_1710821266515_117_model_15  0.396675911806772\n",
       "     0.6      0.001     Grid_GLM_Key_Frame__upload_a192a381ec49060d178efde966634972.hex_model_python_1710821266515_117_model_16  0.39668371747676684\n",
       "     0.2      0.001     Grid_GLM_Key_Frame__upload_a192a381ec49060d178efde966634972.hex_model_python_1710821266515_117_model_14  0.396687947456341\n",
       "     1.0      0.001     Grid_GLM_Key_Frame__upload_a192a381ec49060d178efde966634972.hex_model_python_1710821266515_117_model_18  0.3966898370016048\n",
       "     0.8      0.001     Grid_GLM_Key_Frame__upload_a192a381ec49060d178efde966634972.hex_model_python_1710821266515_117_model_17  0.3966903959640893\n",
       "     0.0      0.001     Grid_GLM_Key_Frame__upload_a192a381ec49060d178efde966634972.hex_model_python_1710821266515_117_model_13  0.3967103219267951\n",
       "     1.0      0.0001    Grid_GLM_Key_Frame__upload_a192a381ec49060d178efde966634972.hex_model_python_1710821266515_117_model_12  0.39680812084952916\n",
       "     0.8      0.0001    Grid_GLM_Key_Frame__upload_a192a381ec49060d178efde966634972.hex_model_python_1710821266515_117_model_11  0.39681225494234756\n",
       "     0.6      0.0001    Grid_GLM_Key_Frame__upload_a192a381ec49060d178efde966634972.hex_model_python_1710821266515_117_model_10  0.3968141160834486\n",
       "     0.4      0.0001    Grid_GLM_Key_Frame__upload_a192a381ec49060d178efde966634972.hex_model_python_1710821266515_117_model_9   0.3968163982205071\n",
       "---  ---      ---       ---                                                                                                      ---\n",
       "     1.0      0.3       Grid_GLM_Key_Frame__upload_a192a381ec49060d178efde966634972.hex_model_python_1710821266515_117_model_42  0.4632513970578427\n",
       "     0.4      0.4       Grid_GLM_Key_Frame__upload_a192a381ec49060d178efde966634972.hex_model_python_1710821266515_117_model_45  0.4632513970578427\n",
       "     0.6      0.4       Grid_GLM_Key_Frame__upload_a192a381ec49060d178efde966634972.hex_model_python_1710821266515_117_model_46  0.4632513970578427\n",
       "     0.8      0.4       Grid_GLM_Key_Frame__upload_a192a381ec49060d178efde966634972.hex_model_python_1710821266515_117_model_47  0.4632513970578427\n",
       "     1.0      0.4       Grid_GLM_Key_Frame__upload_a192a381ec49060d178efde966634972.hex_model_python_1710821266515_117_model_48  0.4632513970578427\n",
       "     0.2      0.5       Grid_GLM_Key_Frame__upload_a192a381ec49060d178efde966634972.hex_model_python_1710821266515_117_model_50  0.4632513970578427\n",
       "     0.4      0.5       Grid_GLM_Key_Frame__upload_a192a381ec49060d178efde966634972.hex_model_python_1710821266515_117_model_51  0.4632513970578427\n",
       "     0.6      0.5       Grid_GLM_Key_Frame__upload_a192a381ec49060d178efde966634972.hex_model_python_1710821266515_117_model_52  0.4632513970578427\n",
       "     0.8      0.5       Grid_GLM_Key_Frame__upload_a192a381ec49060d178efde966634972.hex_model_python_1710821266515_117_model_53  0.4632513970578427\n",
       "     1.0      0.5       Grid_GLM_Key_Frame__upload_a192a381ec49060d178efde966634972.hex_model_python_1710821266515_117_model_54  0.4632513970578427\n",
       "[54 rows x 5 columns]\n"
      ]
     },
     "execution_count": 571,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from h2o.grid.grid_search import H2OGridSearch\n",
    "\n",
    "hyper_params = {\n",
    "    'alpha': [0, 0.2, 0.4, 0.6, 0.8, 1],  # Regularization type mix\n",
    "    'lambda': [1e-5, 1e-4, 1e-3, 1e-2, 0.1, 0.2, 0.3, 0.4, 0.5],  # Regularization strength\n",
    "}\n",
    "\n",
    "# Set up Grid Search\n",
    "grid = H2OGridSearch(model=H2OGeneralizedLinearEstimator(family=\"binomial\"),\n",
    "                     hyper_params=hyper_params,\n",
    "                     search_criteria={'strategy': \"Cartesian\"})\n",
    "\n",
    "# Train the model\n",
    "grid.train(x=feature_cols, y=target_col, training_frame=training_frame,validation_frame=validation_frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "b1297fe3-fa97-44cd-a6d6-0c4c5e7bbfb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      alpha   lambda                                          model_ids  \\\n",
      "0       0.4  0.00100  Grid_GLM_Key_Frame__upload_a192a381ec49060d178...   \n",
      "1       0.6  0.00100  Grid_GLM_Key_Frame__upload_a192a381ec49060d178...   \n",
      "2       0.2  0.00100  Grid_GLM_Key_Frame__upload_a192a381ec49060d178...   \n",
      "3       1.0  0.00100  Grid_GLM_Key_Frame__upload_a192a381ec49060d178...   \n",
      "4       0.8  0.00100  Grid_GLM_Key_Frame__upload_a192a381ec49060d178...   \n",
      "5       0.0  0.00100  Grid_GLM_Key_Frame__upload_a192a381ec49060d178...   \n",
      "6       1.0  0.00010  Grid_GLM_Key_Frame__upload_a192a381ec49060d178...   \n",
      "7       0.8  0.00010  Grid_GLM_Key_Frame__upload_a192a381ec49060d178...   \n",
      "8       0.6  0.00010  Grid_GLM_Key_Frame__upload_a192a381ec49060d178...   \n",
      "9       0.4  0.00010  Grid_GLM_Key_Frame__upload_a192a381ec49060d178...   \n",
      "10      0.0  0.00010  Grid_GLM_Key_Frame__upload_a192a381ec49060d178...   \n",
      "11      0.2  0.00010  Grid_GLM_Key_Frame__upload_a192a381ec49060d178...   \n",
      "12      0.0  0.00001  Grid_GLM_Key_Frame__upload_a192a381ec49060d178...   \n",
      "13      0.2  0.00001  Grid_GLM_Key_Frame__upload_a192a381ec49060d178...   \n",
      "14      0.8  0.00001  Grid_GLM_Key_Frame__upload_a192a381ec49060d178...   \n",
      "15      0.4  0.00001  Grid_GLM_Key_Frame__upload_a192a381ec49060d178...   \n",
      "16      1.0  0.00001  Grid_GLM_Key_Frame__upload_a192a381ec49060d178...   \n",
      "17      0.6  0.00001  Grid_GLM_Key_Frame__upload_a192a381ec49060d178...   \n",
      "18      0.0  0.01000  Grid_GLM_Key_Frame__upload_a192a381ec49060d178...   \n",
      "19      0.2  0.01000  Grid_GLM_Key_Frame__upload_a192a381ec49060d178...   \n",
      "20      0.4  0.01000  Grid_GLM_Key_Frame__upload_a192a381ec49060d178...   \n",
      "21      0.6  0.01000  Grid_GLM_Key_Frame__upload_a192a381ec49060d178...   \n",
      "22      0.8  0.01000  Grid_GLM_Key_Frame__upload_a192a381ec49060d178...   \n",
      "23      1.0  0.01000  Grid_GLM_Key_Frame__upload_a192a381ec49060d178...   \n",
      "24      0.0  0.10000  Grid_GLM_Key_Frame__upload_a192a381ec49060d178...   \n",
      "25      0.0  0.20000  Grid_GLM_Key_Frame__upload_a192a381ec49060d178...   \n",
      "26      0.2  0.10000  Grid_GLM_Key_Frame__upload_a192a381ec49060d178...   \n",
      "27      0.0  0.30000  Grid_GLM_Key_Frame__upload_a192a381ec49060d178...   \n",
      "28      0.0  0.40000  Grid_GLM_Key_Frame__upload_a192a381ec49060d178...   \n",
      "29      0.0  0.50000  Grid_GLM_Key_Frame__upload_a192a381ec49060d178...   \n",
      "30      0.4  0.10000  Grid_GLM_Key_Frame__upload_a192a381ec49060d178...   \n",
      "31      0.2  0.20000  Grid_GLM_Key_Frame__upload_a192a381ec49060d178...   \n",
      "32      0.6  0.10000  Grid_GLM_Key_Frame__upload_a192a381ec49060d178...   \n",
      "33      0.2  0.30000  Grid_GLM_Key_Frame__upload_a192a381ec49060d178...   \n",
      "34      0.8  0.10000  Grid_GLM_Key_Frame__upload_a192a381ec49060d178...   \n",
      "35      0.4  0.20000  Grid_GLM_Key_Frame__upload_a192a381ec49060d178...   \n",
      "36      0.2  0.40000  Grid_GLM_Key_Frame__upload_a192a381ec49060d178...   \n",
      "37      1.0  0.10000  Grid_GLM_Key_Frame__upload_a192a381ec49060d178...   \n",
      "38      0.6  0.20000  Grid_GLM_Key_Frame__upload_a192a381ec49060d178...   \n",
      "39      0.8  0.20000  Grid_GLM_Key_Frame__upload_a192a381ec49060d178...   \n",
      "40      1.0  0.20000  Grid_GLM_Key_Frame__upload_a192a381ec49060d178...   \n",
      "41      0.4  0.30000  Grid_GLM_Key_Frame__upload_a192a381ec49060d178...   \n",
      "42      0.6  0.30000  Grid_GLM_Key_Frame__upload_a192a381ec49060d178...   \n",
      "43      0.8  0.30000  Grid_GLM_Key_Frame__upload_a192a381ec49060d178...   \n",
      "44      1.0  0.30000  Grid_GLM_Key_Frame__upload_a192a381ec49060d178...   \n",
      "45      0.4  0.40000  Grid_GLM_Key_Frame__upload_a192a381ec49060d178...   \n",
      "46      0.6  0.40000  Grid_GLM_Key_Frame__upload_a192a381ec49060d178...   \n",
      "47      0.8  0.40000  Grid_GLM_Key_Frame__upload_a192a381ec49060d178...   \n",
      "48      1.0  0.40000  Grid_GLM_Key_Frame__upload_a192a381ec49060d178...   \n",
      "49      0.2  0.50000  Grid_GLM_Key_Frame__upload_a192a381ec49060d178...   \n",
      "50      0.4  0.50000  Grid_GLM_Key_Frame__upload_a192a381ec49060d178...   \n",
      "51      0.6  0.50000  Grid_GLM_Key_Frame__upload_a192a381ec49060d178...   \n",
      "52      0.8  0.50000  Grid_GLM_Key_Frame__upload_a192a381ec49060d178...   \n",
      "53      1.0  0.50000  Grid_GLM_Key_Frame__upload_a192a381ec49060d178...   \n",
      "\n",
      "     logloss  \n",
      "0   0.396676  \n",
      "1   0.396684  \n",
      "2   0.396688  \n",
      "3   0.396690  \n",
      "4   0.396690  \n",
      "5   0.396710  \n",
      "6   0.396808  \n",
      "7   0.396812  \n",
      "8   0.396814  \n",
      "9   0.396816  \n",
      "10  0.396817  \n",
      "11  0.396817  \n",
      "12  0.396830  \n",
      "13  0.396831  \n",
      "14  0.396832  \n",
      "15  0.396832  \n",
      "16  0.396832  \n",
      "17  0.396833  \n",
      "18  0.396885  \n",
      "19  0.397239  \n",
      "20  0.397693  \n",
      "21  0.398056  \n",
      "22  0.398459  \n",
      "23  0.398654  \n",
      "24  0.405478  \n",
      "25  0.411770  \n",
      "26  0.413109  \n",
      "27  0.416428  \n",
      "28  0.420165  \n",
      "29  0.423285  \n",
      "30  0.423983  \n",
      "31  0.431502  \n",
      "32  0.439030  \n",
      "33  0.448721  \n",
      "34  0.452244  \n",
      "35  0.456300  \n",
      "36  0.459192  \n",
      "37  0.463251  \n",
      "38  0.463251  \n",
      "39  0.463251  \n",
      "40  0.463251  \n",
      "41  0.463251  \n",
      "42  0.463251  \n",
      "43  0.463251  \n",
      "44  0.463251  \n",
      "45  0.463251  \n",
      "46  0.463251  \n",
      "47  0.463251  \n",
      "48  0.463251  \n",
      "49  0.463251  \n",
      "50  0.463251  \n",
      "51  0.463251  \n",
      "52  0.463251  \n",
      "53  0.463251  \n"
     ]
    }
   ],
   "source": [
    "# Get the grid search results\n",
    "grid_results = grid.sorted_metric_table()\n",
    "print(grid_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32f1483-22a0-439a-8462-e36d15ec677d",
   "metadata": {},
   "source": [
    "# Best model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed2b7b6-ca6c-4284-9865-e802e5a18695",
   "metadata": {},
   "source": [
    "We extract the best model and identify the model metrics and performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "id": "33383d82-023b-49b7-a0fe-1db32eac5815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model performance:  ModelMetricsBinomialGLM: glm\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 0.11991867473761374\n",
      "RMSE: 0.34629275871379944\n",
      "LogLoss: 0.3826531738045614\n",
      "AUC: 0.7839834488089299\n",
      "AUCPR: 0.4551406224152404\n",
      "Gini: 0.5679668976178598\n",
      "Null degrees of freedom: 720228\n",
      "Residual degrees of freedom: 720197\n",
      "Null deviance: 668474.1727504975\n",
      "Residual deviance: 551195.8254321709\n",
      "AIC: 551259.8254321709\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.23788064268767925\n",
      "       0       1       Error    Rate\n",
      "-----  ------  ------  -------  -------------------\n",
      "0      474334  119695  0.2015   (119695.0/594029.0)\n",
      "1      50286   75914   0.3985   (50286.0/126200.0)\n",
      "Total  524620  195609  0.236    (169981.0/720229.0)\n",
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "metric                       threshold    value     idx\n",
      "---------------------------  -----------  --------  -----\n",
      "max f1                       0.237881     0.471795  222\n",
      "max f2                       0.129904     0.60401   293\n",
      "max f0point5                 0.372132     0.464379  150\n",
      "max accuracy                 0.514932     0.836633  91\n",
      "max precision                0.961166     1         0\n",
      "max recall                   0.00305685   1         396\n",
      "max specificity              0.961166     1         0\n",
      "max absolute_mcc             0.263967     0.342863  207\n",
      "max min_per_class_accuracy   0.186108     0.709198  254\n",
      "max mean_per_class_accuracy  0.17969      0.710606  258\n",
      "max tns                      0.961166     594029    0\n",
      "max fns                      0.961166     126181    0\n",
      "max fps                      0.00105188   594029    399\n",
      "max tps                      0.00305685   126200    396\n",
      "max tnr                      0.961166     1         0\n",
      "max fnr                      0.961166     0.999849  0\n",
      "max fpr                      0.00105188   1         399\n",
      "max tpr                      0.00305685   1         396\n",
      "\n",
      "Gains/Lift Table: Avg response rate: 17.52 %, avg score: 17.52 %\n",
      "group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
      "-------  --------------------------  -----------------  ---------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
      "1        0.010001                    0.690337           4.41636    4.41636            0.773844         0.75814     0.773844                    0.75814             0.044168        0.044168                   341.636   341.636            0.0414257\n",
      "2        0.0200006                   0.622334           3.78541    4.10091            0.663288         0.654731    0.71857                     0.706439            0.0378526       0.0820206                  278.541   310.091            0.075196\n",
      "3        0.0300002                   0.569557           3.38445    3.8621             0.59303          0.595077    0.676725                    0.66932             0.0338431       0.115864                   238.445   286.21             0.104105\n",
      "4        0.0400012                   0.528268           3.14391    3.68254            0.550882         0.548355    0.645262                    0.639077            0.0314422       0.147306                   214.391   268.254            0.130101\n",
      "5        0.0500008                   0.491968           2.87729    3.5215             0.504166         0.509443    0.617044                    0.613152            0.0287718       0.176078                   187.729   252.15             0.152862\n",
      "6        0.1                         0.396741           2.53442    3.02797            0.444087         0.43796     0.530567                    0.525557            0.126719        0.302797                   153.442   202.797            0.245881\n",
      "7        0.150001                    0.33698            2.07857    2.7115             0.364212         0.365016    0.475115                    0.472043            0.10393         0.406727                   107.857   171.15             0.311267\n",
      "8        0.2                         0.290532           1.76959    2.47603            0.310072         0.313133    0.433854                    0.432316            0.0884786       0.495206                   76.9594   147.603            0.357921\n",
      "9        0.3                         0.21891            1.42575    2.12593            0.249823         0.252645    0.372511                    0.372426            0.142575        0.637781                   42.5751   112.593            0.409542\n",
      "10       0.400001                    0.168702           1.08883    1.86666            0.190786         0.192719    0.32708                     0.327499            0.108883        0.746664                   8.88257   86.6657            0.420311\n",
      "11       0.500001                    0.127871           0.810775   1.65548            0.142066         0.147585    0.290077                    0.291516            0.0810777       0.827742                   -18.9225  65.5481            0.397369\n",
      "12       0.599999                    0.0951467          0.61435    1.48196            0.107648         0.110885    0.259672                    0.261411            0.0614342       0.889176                   -38.565   48.1961            0.350611\n",
      "13       0.7                         0.0689907          0.476703   1.33835            0.0835289        0.0815569   0.234509                    0.235718            0.0476704       0.936846                   -52.3297  33.8353            0.287164\n",
      "14       0.8                         0.0472257          0.355546   1.2155             0.0622995        0.0578876   0.212983                    0.213489            0.0355547       0.972401                   -64.4454  21.5502            0.209027\n",
      "15       0.9                         0.0231075          0.241283   1.10725            0.0422782        0.0359783   0.194015                    0.193766            0.0241284       0.996529                   -75.8717  10.7255            0.117037\n",
      "16       1                           7.71405e-09        0.0347068  1                  0.00608139       0.00851534  0.175222                    0.175241            0.00347068      1                          -96.5293  0                  0\n"
     ]
    }
   ],
   "source": [
    "# print best model performance metrics\n",
    "best_model = grid.get_grid(sort_by=\"auc\", decreasing=True).models[0]\n",
    "print(\"Best model performance: \", best_model.model_performance(training_frame))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbd049d-8196-4d1f-9f16-9ca7671f0bf5",
   "metadata": {},
   "source": [
    "# SUMMARY OF THE PROJECT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e5c220-c677-4443-a882-c4f43e3a0871",
   "metadata": {},
   "source": [
    "**The project primarily focued on the SBA loans dataset. After data cleaning and EDA we used feature engineering to create better features for our model. The project included the use of logistic regression in both sklearn and h20. The logistic regression models used were experimented with multiple hyperparamreters using gridsearch and the ideal set of parameters was identified. The feature engineering step helped decrease multicollinearity by using PCA and further using feature selection/ViF helped improve performance. From the observations made, the best model had no regularization and performed with an f1 macro score of 0.65 and accuracy of 76%. On further analysis using Scoring function and the kaggle submission board, a score of 76.45% was obtained. On the H20 side our best model performs with an AUC score of 0.78 and AIC of 551259.8254321709. we experimented with multiple regularizations and regularization strenghts. The sklearn model was used for our scoring function since it gave us the best results. The ideal threshold after using f1 macro was 0.54. \n",
    "Moving forward a set of recommendations would primarily focus on experimenting with other models that deal better with data imbalance. Another approach could be used data resampling such as oversampling and undersampling the data to try improving model performance. Lastly more engineered features which increase explainability could ultimately result in a better model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbc39d6-1587-46ce-b4a9-cef5c12602fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
