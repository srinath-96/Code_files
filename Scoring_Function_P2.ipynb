{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bd66f2c-fa02-4e0a-b740-1a95c60a73ac",
   "metadata": {},
   "source": [
    "# SCORING FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dcf6f7-6c79-4bba-873f-da8cec7d183a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needs to be run to make sure there is no version mismatch\n",
    "!pip install scikit-learn==1.0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d4e9cd8-3026-47a5-86d6-4665513da400",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40c6f57b-d884-4169-92e6-9351af4df4f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.3.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d08d783-1491-4014-96d2-94d820626ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_2_scoring(data):\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    from copy import deepcopy\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    import pickle\n",
    "    import category_encoders as ce\n",
    "    import numpy as np\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    # we deep copy original data\n",
    "    X_train= data.copy()\n",
    "    #replacing values in RevLineCr with Y and N\n",
    "    X_train['RevLineCr']=X_train['RevLineCr'].replace('0','N')\n",
    "    X_train['RevLineCr']=X_train['RevLineCr'].replace('1','Y')\n",
    "    X_train['RevLineCr']=X_train['RevLineCr'].replace('T','Y')\n",
    "    #replacing values in RevLineCr with null that have no context\n",
    "    X_train['RevLineCr'] = X_train['RevLineCr'].apply(lambda x: x if x in ['Y', 'N'] else np.nan)\n",
    "\n",
    "    \n",
    "    X_train['RevLineCr'].fillna(X_train['RevLineCr'].mode()[0], inplace=True)\n",
    "\n",
    "    #replacing values in LowDoc with Y and N\n",
    "    X_train['LowDoc']=X_train['LowDoc'].replace('0','N')\n",
    "    X_train['LowDoc']=X_train['LowDoc'].replace('S','Y')\n",
    "    X_train['LowDoc']=X_train['LowDoc'].replace('A','N')\n",
    "    \n",
    "    X_train['LowDoc'] = X_train['LowDoc'].apply(lambda x: x if x in ['Y', 'N'] else np.nan)\n",
    "\n",
    "\n",
    "    X_train['LowDoc'].fillna(X_train['LowDoc'].mode()[0], inplace=True)\n",
    "\n",
    "    #extract index column \n",
    "    index=X_train[['index']]\n",
    "    X_train.drop('index',inplace=True,axis=1,errors='ignore')\n",
    "    cat=[]\n",
    "    num=[]\n",
    "    colu=[]\n",
    "    for col in X_train.columns:\n",
    "        if X_train[col].isna().any() == True:\n",
    "            colu.append(col)\n",
    "    num=[col for col in colu if (X_train[col].dtype != 'object') ] \n",
    "    cat=[col for col in colu if (X_train[col].dtype == 'object') ]\n",
    "    #imputing null values\n",
    "    for i in cat:\n",
    "        X_train[i].fillna(X_train[i].mode().iloc[0],inplace=True)\n",
    "    for i in num:\n",
    "        X_train[i].fillna(X_train[i].median(),inplace=True)\n",
    "    # Fearure engineering\n",
    "    # Feature 1: Loan Size Category\n",
    "    X_train['LoanSizeCategory'] = pd.cut(X_train['GrAppv'], bins=[0, 50000, 150000, 350000, 1000000, 5000000], labels=['Micro', 'Small', 'Medium', 'Large', 'Very Large'])\n",
    "\n",
    "        # Feature 2: Job Creation Category\n",
    "    X_train['JobCreationCategory'] = pd.cut(X_train['CreateJob'] + X_train['RetainedJob'], bins=[-1, 0, 5, 10, 20, 50, 100, float('inf')], labels=['None', 'Few', 'Some', 'Moderate', 'Many', 'A Lot', 'Massive'])\n",
    "\n",
    "        # Feature 3: High-Risk Industry (NAICS codes starting with 72 are typically hospitality, considered higher risk)\n",
    "    X_train['HighRiskIndustry'] = X_train['NAICS'].apply(lambda x: 1 if str(x).startswith('72') else 0)\n",
    "\n",
    "        # Feature 4: Loan/Grant Ratio\n",
    "    X_train['LoanGrantRatio'] = X_train['GrAppv'] / X_train['SBA_Appv']\n",
    "\n",
    "        # Feature 5: Per Employee Investment\n",
    "    X_train['PerEmployeeInvestment'] = X_train['GrAppv'] / (X_train['NoEmp'] + 1)  # Avoid division by zero\n",
    "\n",
    "\n",
    "\n",
    "        # Feature 6: Business Age - New business flag (assuming NewExist codes: 1 for existing, 2 for new)\n",
    "    X_train['NewBusiness'] = X_train['NewExist'].apply(lambda x: 1 if x == 2 else 0)\n",
    "\n",
    "        # Feature 7: Urban Business - Flag for businesses in urban areas (assuming UrbanRural codes: 1 for urban, 2 for rural, 0 for undefined)\n",
    "    X_train['UrbanBusiness'] = X_train['UrbanRural'].apply(lambda x: 1 if x == 1 else 0)\n",
    "\n",
    "        # Feature 8: Franchise Flag - Flag for whether the business is a franchise (assuming FranchiseCode: 1 or 0 indicates not a franchise, any other value indicates a franchise)\n",
    "    X_train['FranchiseFlag'] = X_train['FranchiseCode'].apply(lambda x: 0 if x == 1 or x == 0 else 1)\n",
    "\n",
    "        # Feature 9: Expansion Plan - Flag businesses creating more jobs than retaining (CreateJob > RetainedJob)\n",
    "    X_train['ExpansionPlan'] = X_train.apply(lambda x: 1 if x['CreateJob'] > x['RetainedJob'] else 0, axis=1)\n",
    "\n",
    "        # Feature 10: Economic Sector - Extract broader economic sector from NAICS code (first two digits of NAICS code)\n",
    "    X_train['EconomicSector'] = X_train['NAICS'].apply(lambda x: int(str(x)[:2]) if x > 0 else 0)\n",
    "\n",
    "    # Feature 11: Credit Utilization Ratio\n",
    "    X_train['CreditUtilizationRatio'] = X_train['GrAppv'] / X_train['SBA_Appv']\n",
    "\n",
    "# Feature 12: Profitability Indicator (Profitability as Retained Jobs greater than Created Jobs)\n",
    "    X_train['ProfitabilityIndicator'] = (X_train['RetainedJob'] > X_train['CreateJob']).astype(int)\n",
    "\n",
    "# Feature 13: Seasonal Adjustment (Seasonal industries, e.g., Retail in Q4 - Using NAICS)\n",
    "    seasonal_naics = [44, 45]  # Retail trade NAICS codes\n",
    "    X_train['SeasonalAdjustment'] = X_train['NAICS'].apply(lambda x: 1 if int(str(x)[:2]) in seasonal_naics else 0)\n",
    "\n",
    "# Feature 14: Geographic Region (Categorizing ZIP codes into regions, assuming arbitrary division for example)\n",
    "    X_train['GeographicRegion'] = pd.cut(X_train['Zip'], bins=4, labels=['North', 'South', 'East', 'West'])\n",
    "\n",
    "# Feature 15: Loan Size per Employee\n",
    "    X_train['LoanPerEmployee'] = X_train['GrAppv'] / (X_train['NoEmp'] + 1)  # Adding 1 to avoid division by zero\n",
    "\n",
    "    for col in X_train.select_dtypes(include=['category']).columns:\n",
    "        X_train[col] = X_train[col].astype('object')\n",
    "    # Identify categorical variables with less than 10 unique values for one-hot encoding\n",
    "    cat_vars_for_one_hot = [col for col in X_train.columns if (X_train[col].nunique() < 10) and (X_train[col].dtype == 'object')]\n",
    "\n",
    "    # Now, for target and WOE encoding, identify the remaining categorical variables\n",
    "    remaining_cat_vars = [col for col in X_train.columns if (X_train[col].dtype == 'object') and (col not in cat_vars_for_one_hot)]\n",
    "\n",
    "    numeric=[col for col in X_train.columns if (X_train[col].dtype != 'object') ]\n",
    "\n",
    "    #importing trained encoders/scalers\n",
    "    with open('woe_encoder.pkl', 'rb') as file:\n",
    "        loaded_woe_encoder = pd.read_pickle(file)\n",
    "    with open('standardscaler.pkl', 'rb') as file:\n",
    "        loaded_scaler = pd.read_pickle(file)\n",
    "    with open('onehot_encoder.pkl', 'rb') as file:\n",
    "        loaded_onehot_encoder = pd.read_pickle(file)\n",
    "    drops=['NewExist','CreateJob','RetainedJob','NAICS','GrAppv','SBA_Appv']\n",
    "    res = [item for item in numeric if item not in drops]\n",
    "    \n",
    "    X_train = X_train.join(loaded_woe_encoder.transform(X_train[remaining_cat_vars]).add_suffix('_woe'))\n",
    "    \n",
    "    X_train[res] = loaded_scaler.transform(X_train[res])\n",
    "    \n",
    "    X_train.drop(columns=remaining_cat_vars,axis=1,inplace=True,errors='ignore')\n",
    "    X_train.drop(columns=drops,axis=1,inplace=True,errors='ignore')\n",
    "\n",
    "    X_train_ohe = loaded_onehot_encoder.transform(X_train[cat_vars_for_one_hot])\n",
    "    # Convert to DataFrame and name columns\n",
    "    columns = loaded_onehot_encoder.get_feature_names_out(cat_vars_for_one_hot)\n",
    "    X_train_ohe = pd.DataFrame(X_train_ohe, columns=columns, index=X_train.index)\n",
    "\n",
    "    X_train = pd.concat([X_train.drop(columns=cat_vars_for_one_hot), X_train_ohe], axis=1)\n",
    "    #importing trained logreg model\n",
    "    with open('xgb_model.pkl', 'rb') as file:\n",
    "        loaded_model = pd.read_pickle(file)\n",
    "    y_pred_proba = loaded_model.predict_proba(X_train)\n",
    "    y_pred = (y_pred_proba[:,1] > 0.63).astype(np.int16)\n",
    "    d = {\"index\":index.to_numpy().ravel(),\n",
    "             \"label\":y_pred,\n",
    "             \"probability_0\":y_pred_proba[:,0],\n",
    "             \"probability_1\":y_pred_proba[:,1]}\n",
    "\n",
    "    return pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a4a1e34-e516-45d0-969e-999f66335639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "      <th>probability_0</th>\n",
       "      <th>probability_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.786404</td>\n",
       "      <td>0.213596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.672249</td>\n",
       "      <td>0.327751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.695789</td>\n",
       "      <td>0.304211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.872023</td>\n",
       "      <td>0.127977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.728167</td>\n",
       "      <td>0.271833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99803</th>\n",
       "      <td>99803</td>\n",
       "      <td>1</td>\n",
       "      <td>0.342779</td>\n",
       "      <td>0.657221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99804</th>\n",
       "      <td>99804</td>\n",
       "      <td>0</td>\n",
       "      <td>0.806731</td>\n",
       "      <td>0.193269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99805</th>\n",
       "      <td>99805</td>\n",
       "      <td>0</td>\n",
       "      <td>0.871434</td>\n",
       "      <td>0.128566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99806</th>\n",
       "      <td>99806</td>\n",
       "      <td>0</td>\n",
       "      <td>0.706304</td>\n",
       "      <td>0.293696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99807</th>\n",
       "      <td>99807</td>\n",
       "      <td>1</td>\n",
       "      <td>0.347857</td>\n",
       "      <td>0.652143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99808 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index  label  probability_0  probability_1\n",
       "0          0      0       0.786404       0.213596\n",
       "1          1      0       0.672249       0.327751\n",
       "2          2      0       0.695789       0.304211\n",
       "3          3      0       0.872023       0.127977\n",
       "4          4      0       0.728167       0.271833\n",
       "...      ...    ...            ...            ...\n",
       "99803  99803      1       0.342779       0.657221\n",
       "99804  99804      0       0.806731       0.193269\n",
       "99805  99805      0       0.871434       0.128566\n",
       "99806  99806      0       0.706304       0.293696\n",
       "99807  99807      1       0.347857       0.652143\n",
       "\n",
       "[99808 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('SBA_loans_project_2_holdout_students_valid.csv')\n",
    "x=project_2_scoring(data)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1189d645-0ed4-4db3-9a4c-93417f768edf",
   "metadata": {},
   "source": [
    "# KAGGLE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b172adb-2027-4c9d-9a3b-bb35af445379",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x3/5n0yyb7911zg532jx71xlkrr0000gn/T/ipykernel_56916/1532254769.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x.rename(columns={'index': 'ID'}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "x=x[['index','probability_1']]\n",
    "x.rename(columns={'index': 'ID'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "505493dd-e255-4ce1-9c2d-0efb135af8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/IPython/core/formatters.py:343: FutureWarning: Index.format is deprecated and will be removed in a future version. Convert using index.astype(str) or index.map(formatter) instead.\n",
      "  return method()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>probability_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.213596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.327751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.304211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.127977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.271833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99803</th>\n",
       "      <td>99803</td>\n",
       "      <td>0.657221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99804</th>\n",
       "      <td>99804</td>\n",
       "      <td>0.193269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99805</th>\n",
       "      <td>99805</td>\n",
       "      <td>0.128566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99806</th>\n",
       "      <td>99806</td>\n",
       "      <td>0.293696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99807</th>\n",
       "      <td>99807</td>\n",
       "      <td>0.652143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99808 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  probability_1\n",
       "0          0       0.213596\n",
       "1          1       0.327751\n",
       "2          2       0.304211\n",
       "3          3       0.127977\n",
       "4          4       0.271833\n",
       "...      ...            ...\n",
       "99803  99803       0.657221\n",
       "99804  99804       0.193269\n",
       "99805  99805       0.128566\n",
       "99806  99806       0.293696\n",
       "99807  99807       0.652143\n",
       "\n",
       "[99808 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "614073e0-ca1f-4a78-bf3c-e095a12638b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "write() got an unexpected keyword argument 'engine_kwargs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msubmission.xlsx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py:333\u001b[0m, in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    326\u001b[0m         warnings.warn(\n\u001b[1;32m    327\u001b[0m             msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m             FutureWarning,\n\u001b[1;32m    329\u001b[0m             stacklevel=find_stack_level(),\n\u001b[1;32m    330\u001b[0m         )\n\u001b[1;32m    331\u001b[0m     return func(*args, **kwargs)\n\u001b[0;32m--> 333\u001b[0m # error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\n\u001b[1;32m    334\u001b[0m # attribute \"__signature__\"\n\u001b[1;32m    335\u001b[0m wrapper.__signature__ = new_sig  # type: ignore[attr-defined]\n\u001b[1;32m    336\u001b[0m return wrapper\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py:2417\u001b[0m, in \u001b[0;36mto_excel\u001b[0;34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, inf_rep, freeze_panes, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   2384\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   2385\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[1;32m   2386\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m_shared_docs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2402\u001b[0m     storage_options: StorageOptions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2403\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2404\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2405\u001b[0m \u001b[38;5;124;03m    Convert the object to a JSON string.\u001b[39;00m\n\u001b[1;32m   2406\u001b[0m \n\u001b[1;32m   2407\u001b[0m \u001b[38;5;124;03m    Note NaN's and None will be converted to null and datetime objects\u001b[39;00m\n\u001b[1;32m   2408\u001b[0m \u001b[38;5;124;03m    will be converted to UNIX timestamps.\u001b[39;00m\n\u001b[1;32m   2409\u001b[0m \n\u001b[1;32m   2410\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   2411\u001b[0m \u001b[38;5;124;03m    ----------\u001b[39;00m\n\u001b[1;32m   2412\u001b[0m \u001b[38;5;124;03m    path_or_buf : str, path object, file-like object, or None, default None\u001b[39;00m\n\u001b[1;32m   2413\u001b[0m \u001b[38;5;124;03m        String, path object (implementing os.PathLike[str]), or file-like\u001b[39;00m\n\u001b[1;32m   2414\u001b[0m \u001b[38;5;124;03m        object implementing a write() function. If None, the result is\u001b[39;00m\n\u001b[1;32m   2415\u001b[0m \u001b[38;5;124;03m        returned as a string.\u001b[39;00m\n\u001b[1;32m   2416\u001b[0m \u001b[38;5;124;03m    orient : str\u001b[39;00m\n\u001b[0;32m-> 2417\u001b[0m \u001b[38;5;124;03m        Indication of expected JSON string format.\u001b[39;00m\n\u001b[1;32m   2418\u001b[0m \n\u001b[1;32m   2419\u001b[0m \u001b[38;5;124;03m        * Series:\u001b[39;00m\n\u001b[1;32m   2420\u001b[0m \n\u001b[1;32m   2421\u001b[0m \u001b[38;5;124;03m            - default is 'index'\u001b[39;00m\n\u001b[1;32m   2422\u001b[0m \u001b[38;5;124;03m            - allowed values are: {{'split', 'records', 'index', 'table'}}.\u001b[39;00m\n\u001b[1;32m   2423\u001b[0m \n\u001b[1;32m   2424\u001b[0m \u001b[38;5;124;03m        * DataFrame:\u001b[39;00m\n\u001b[1;32m   2425\u001b[0m \n\u001b[1;32m   2426\u001b[0m \u001b[38;5;124;03m            - default is 'columns'\u001b[39;00m\n\u001b[1;32m   2427\u001b[0m \u001b[38;5;124;03m            - allowed values are: {{'split', 'records', 'index', 'columns',\u001b[39;00m\n\u001b[1;32m   2428\u001b[0m \u001b[38;5;124;03m              'values', 'table'}}.\u001b[39;00m\n\u001b[1;32m   2429\u001b[0m \n\u001b[1;32m   2430\u001b[0m \u001b[38;5;124;03m        * The format of the JSON string:\u001b[39;00m\n\u001b[1;32m   2431\u001b[0m \n\u001b[1;32m   2432\u001b[0m \u001b[38;5;124;03m            - 'split' : dict like {{'index' -> [index], 'columns' -> [columns],\u001b[39;00m\n\u001b[1;32m   2433\u001b[0m \u001b[38;5;124;03m              'data' -> [values]}}\u001b[39;00m\n\u001b[1;32m   2434\u001b[0m \u001b[38;5;124;03m            - 'records' : list like [{{column -> value}}, ... , {{column -> value}}]\u001b[39;00m\n\u001b[1;32m   2435\u001b[0m \u001b[38;5;124;03m            - 'index' : dict like {{index -> {{column -> value}}}}\u001b[39;00m\n\u001b[1;32m   2436\u001b[0m \u001b[38;5;124;03m            - 'columns' : dict like {{column -> {{index -> value}}}}\u001b[39;00m\n\u001b[1;32m   2437\u001b[0m \u001b[38;5;124;03m            - 'values' : just the values array\u001b[39;00m\n\u001b[1;32m   2438\u001b[0m \u001b[38;5;124;03m            - 'table' : dict like {{'schema': {{schema}}, 'data': {{data}}}}\u001b[39;00m\n\u001b[1;32m   2439\u001b[0m \n\u001b[1;32m   2440\u001b[0m \u001b[38;5;124;03m            Describing the data, where data component is like ``orient='records'``.\u001b[39;00m\n\u001b[1;32m   2441\u001b[0m \n\u001b[1;32m   2442\u001b[0m \u001b[38;5;124;03m    date_format : {{None, 'epoch', 'iso'}}\u001b[39;00m\n\u001b[1;32m   2443\u001b[0m \u001b[38;5;124;03m        Type of date conversion. 'epoch' = epoch milliseconds,\u001b[39;00m\n\u001b[1;32m   2444\u001b[0m \u001b[38;5;124;03m        'iso' = ISO8601. The default depends on the `orient`. For\u001b[39;00m\n\u001b[1;32m   2445\u001b[0m \u001b[38;5;124;03m        ``orient='table'``, the default is 'iso'. For all other orients,\u001b[39;00m\n\u001b[1;32m   2446\u001b[0m \u001b[38;5;124;03m        the default is 'epoch'.\u001b[39;00m\n\u001b[1;32m   2447\u001b[0m \u001b[38;5;124;03m    double_precision : int, default 10\u001b[39;00m\n\u001b[1;32m   2448\u001b[0m \u001b[38;5;124;03m        The number of decimal places to use when encoding\u001b[39;00m\n\u001b[1;32m   2449\u001b[0m \u001b[38;5;124;03m        floating point values.\u001b[39;00m\n\u001b[1;32m   2450\u001b[0m \u001b[38;5;124;03m    force_ascii : bool, default True\u001b[39;00m\n\u001b[1;32m   2451\u001b[0m \u001b[38;5;124;03m        Force encoded string to be ASCII.\u001b[39;00m\n\u001b[1;32m   2452\u001b[0m \u001b[38;5;124;03m    date_unit : str, default 'ms' (milliseconds)\u001b[39;00m\n\u001b[1;32m   2453\u001b[0m \u001b[38;5;124;03m        The time unit to encode to, governs timestamp and ISO8601\u001b[39;00m\n\u001b[1;32m   2454\u001b[0m \u001b[38;5;124;03m        precision.  One of 's', 'ms', 'us', 'ns' for second, millisecond,\u001b[39;00m\n\u001b[1;32m   2455\u001b[0m \u001b[38;5;124;03m        microsecond, and nanosecond respectively.\u001b[39;00m\n\u001b[1;32m   2456\u001b[0m \u001b[38;5;124;03m    default_handler : callable, default None\u001b[39;00m\n\u001b[1;32m   2457\u001b[0m \u001b[38;5;124;03m        Handler to call if object cannot otherwise be converted to a\u001b[39;00m\n\u001b[1;32m   2458\u001b[0m \u001b[38;5;124;03m        suitable format for JSON. Should receive a single argument which is\u001b[39;00m\n\u001b[1;32m   2459\u001b[0m \u001b[38;5;124;03m        the object to convert and return a serialisable object.\u001b[39;00m\n\u001b[1;32m   2460\u001b[0m \u001b[38;5;124;03m    lines : bool, default False\u001b[39;00m\n\u001b[1;32m   2461\u001b[0m \u001b[38;5;124;03m        If 'orient' is 'records' write out line-delimited json format. Will\u001b[39;00m\n\u001b[1;32m   2462\u001b[0m \u001b[38;5;124;03m        throw ValueError if incorrect 'orient' since others are not\u001b[39;00m\n\u001b[1;32m   2463\u001b[0m \u001b[38;5;124;03m        list-like.\u001b[39;00m\n\u001b[1;32m   2464\u001b[0m \u001b[38;5;124;03m    {compression_options}\u001b[39;00m\n\u001b[1;32m   2465\u001b[0m \n\u001b[1;32m   2466\u001b[0m \u001b[38;5;124;03m        .. versionchanged:: 1.4.0 Zstandard support.\u001b[39;00m\n\u001b[1;32m   2467\u001b[0m \n\u001b[1;32m   2468\u001b[0m \u001b[38;5;124;03m    index : bool, default True\u001b[39;00m\n\u001b[1;32m   2469\u001b[0m \u001b[38;5;124;03m        Whether to include the index values in the JSON string. Not\u001b[39;00m\n\u001b[1;32m   2470\u001b[0m \u001b[38;5;124;03m        including the index (``index=False``) is only supported when\u001b[39;00m\n\u001b[1;32m   2471\u001b[0m \u001b[38;5;124;03m        orient is 'split' or 'table'.\u001b[39;00m\n\u001b[1;32m   2472\u001b[0m \u001b[38;5;124;03m    indent : int, optional\u001b[39;00m\n\u001b[1;32m   2473\u001b[0m \u001b[38;5;124;03m       Length of whitespace used to indent each record.\u001b[39;00m\n\u001b[1;32m   2474\u001b[0m \n\u001b[1;32m   2475\u001b[0m \u001b[38;5;124;03m       .. versionadded:: 1.0.0\u001b[39;00m\n\u001b[1;32m   2476\u001b[0m \n\u001b[1;32m   2477\u001b[0m \u001b[38;5;124;03m    {storage_options}\u001b[39;00m\n\u001b[1;32m   2478\u001b[0m \n\u001b[1;32m   2479\u001b[0m \u001b[38;5;124;03m        .. versionadded:: 1.2.0\u001b[39;00m\n\u001b[1;32m   2480\u001b[0m \n\u001b[1;32m   2481\u001b[0m \u001b[38;5;124;03m    Returns\u001b[39;00m\n\u001b[1;32m   2482\u001b[0m \u001b[38;5;124;03m    -------\u001b[39;00m\n\u001b[1;32m   2483\u001b[0m \u001b[38;5;124;03m    None or str\u001b[39;00m\n\u001b[1;32m   2484\u001b[0m \u001b[38;5;124;03m        If path_or_buf is None, returns the resulting json format as a\u001b[39;00m\n\u001b[1;32m   2485\u001b[0m \u001b[38;5;124;03m        string. Otherwise returns None.\u001b[39;00m\n\u001b[1;32m   2486\u001b[0m \n\u001b[1;32m   2487\u001b[0m \u001b[38;5;124;03m    See Also\u001b[39;00m\n\u001b[1;32m   2488\u001b[0m \u001b[38;5;124;03m    --------\u001b[39;00m\n\u001b[1;32m   2489\u001b[0m \u001b[38;5;124;03m    read_json : Convert a JSON string to pandas object.\u001b[39;00m\n\u001b[1;32m   2490\u001b[0m \n\u001b[1;32m   2491\u001b[0m \u001b[38;5;124;03m    Notes\u001b[39;00m\n\u001b[1;32m   2492\u001b[0m \u001b[38;5;124;03m    -----\u001b[39;00m\n\u001b[1;32m   2493\u001b[0m \u001b[38;5;124;03m    The behavior of ``indent=0`` varies from the stdlib, which does not\u001b[39;00m\n\u001b[1;32m   2494\u001b[0m \u001b[38;5;124;03m    indent the output but does insert newlines. Currently, ``indent=0``\u001b[39;00m\n\u001b[1;32m   2495\u001b[0m \u001b[38;5;124;03m    and the default ``indent=None`` are equivalent in pandas, though this\u001b[39;00m\n\u001b[1;32m   2496\u001b[0m \u001b[38;5;124;03m    may change in a future release.\u001b[39;00m\n\u001b[1;32m   2497\u001b[0m \n\u001b[1;32m   2498\u001b[0m \u001b[38;5;124;03m    ``orient='table'`` contains a 'pandas_version' field under 'schema'.\u001b[39;00m\n\u001b[1;32m   2499\u001b[0m \u001b[38;5;124;03m    This stores the version of `pandas` used in the latest revision of the\u001b[39;00m\n\u001b[1;32m   2500\u001b[0m \u001b[38;5;124;03m    schema.\u001b[39;00m\n\u001b[1;32m   2501\u001b[0m \n\u001b[1;32m   2502\u001b[0m \u001b[38;5;124;03m    Examples\u001b[39;00m\n\u001b[1;32m   2503\u001b[0m \u001b[38;5;124;03m    --------\u001b[39;00m\n\u001b[1;32m   2504\u001b[0m \u001b[38;5;124;03m    >>> import json\u001b[39;00m\n\u001b[1;32m   2505\u001b[0m \u001b[38;5;124;03m    >>> df = pd.DataFrame(\u001b[39;00m\n\u001b[1;32m   2506\u001b[0m \u001b[38;5;124;03m    ...     [[\"a\", \"b\"], [\"c\", \"d\"]],\u001b[39;00m\n\u001b[1;32m   2507\u001b[0m \u001b[38;5;124;03m    ...     index=[\"row 1\", \"row 2\"],\u001b[39;00m\n\u001b[1;32m   2508\u001b[0m \u001b[38;5;124;03m    ...     columns=[\"col 1\", \"col 2\"],\u001b[39;00m\n\u001b[1;32m   2509\u001b[0m \u001b[38;5;124;03m    ... )\u001b[39;00m\n\u001b[1;32m   2510\u001b[0m \n\u001b[1;32m   2511\u001b[0m \u001b[38;5;124;03m    >>> result = df.to_json(orient=\"split\")\u001b[39;00m\n\u001b[1;32m   2512\u001b[0m \u001b[38;5;124;03m    >>> parsed = json.loads(result)\u001b[39;00m\n\u001b[1;32m   2513\u001b[0m \u001b[38;5;124;03m    >>> json.dumps(parsed, indent=4)  # doctest: +SKIP\u001b[39;00m\n\u001b[1;32m   2514\u001b[0m \u001b[38;5;124;03m    {{\u001b[39;00m\n\u001b[1;32m   2515\u001b[0m \u001b[38;5;124;03m        \"columns\": [\u001b[39;00m\n\u001b[1;32m   2516\u001b[0m \u001b[38;5;124;03m            \"col 1\",\u001b[39;00m\n\u001b[1;32m   2517\u001b[0m \u001b[38;5;124;03m            \"col 2\"\u001b[39;00m\n\u001b[1;32m   2518\u001b[0m \u001b[38;5;124;03m        ],\u001b[39;00m\n\u001b[1;32m   2519\u001b[0m \u001b[38;5;124;03m        \"index\": [\u001b[39;00m\n\u001b[1;32m   2520\u001b[0m \u001b[38;5;124;03m            \"row 1\",\u001b[39;00m\n\u001b[1;32m   2521\u001b[0m \u001b[38;5;124;03m            \"row 2\"\u001b[39;00m\n\u001b[1;32m   2522\u001b[0m \u001b[38;5;124;03m        ],\u001b[39;00m\n\u001b[1;32m   2523\u001b[0m \u001b[38;5;124;03m        \"data\": [\u001b[39;00m\n\u001b[1;32m   2524\u001b[0m \u001b[38;5;124;03m            [\u001b[39;00m\n\u001b[1;32m   2525\u001b[0m \u001b[38;5;124;03m                \"a\",\u001b[39;00m\n\u001b[1;32m   2526\u001b[0m \u001b[38;5;124;03m                \"b\"\u001b[39;00m\n\u001b[1;32m   2527\u001b[0m \u001b[38;5;124;03m            ],\u001b[39;00m\n\u001b[1;32m   2528\u001b[0m \u001b[38;5;124;03m            [\u001b[39;00m\n\u001b[1;32m   2529\u001b[0m \u001b[38;5;124;03m                \"c\",\u001b[39;00m\n\u001b[1;32m   2530\u001b[0m \u001b[38;5;124;03m                \"d\"\u001b[39;00m\n\u001b[1;32m   2531\u001b[0m \u001b[38;5;124;03m            ]\u001b[39;00m\n\u001b[1;32m   2532\u001b[0m \u001b[38;5;124;03m        ]\u001b[39;00m\n\u001b[1;32m   2533\u001b[0m \u001b[38;5;124;03m    }}\u001b[39;00m\n\u001b[1;32m   2534\u001b[0m \n\u001b[1;32m   2535\u001b[0m \u001b[38;5;124;03m    Encoding/decoding a Dataframe using ``'records'`` formatted JSON.\u001b[39;00m\n\u001b[1;32m   2536\u001b[0m \u001b[38;5;124;03m    Note that index labels are not preserved with this encoding.\u001b[39;00m\n\u001b[1;32m   2537\u001b[0m \n\u001b[1;32m   2538\u001b[0m \u001b[38;5;124;03m    >>> result = df.to_json(orient=\"records\")\u001b[39;00m\n\u001b[1;32m   2539\u001b[0m \u001b[38;5;124;03m    >>> parsed = json.loads(result)\u001b[39;00m\n\u001b[1;32m   2540\u001b[0m \u001b[38;5;124;03m    >>> json.dumps(parsed, indent=4)  # doctest: +SKIP\u001b[39;00m\n\u001b[1;32m   2541\u001b[0m \u001b[38;5;124;03m    [\u001b[39;00m\n\u001b[1;32m   2542\u001b[0m \u001b[38;5;124;03m        {{\u001b[39;00m\n\u001b[1;32m   2543\u001b[0m \u001b[38;5;124;03m            \"col 1\": \"a\",\u001b[39;00m\n\u001b[1;32m   2544\u001b[0m \u001b[38;5;124;03m            \"col 2\": \"b\"\u001b[39;00m\n\u001b[1;32m   2545\u001b[0m \u001b[38;5;124;03m        }},\u001b[39;00m\n\u001b[1;32m   2546\u001b[0m \u001b[38;5;124;03m        {{\u001b[39;00m\n\u001b[1;32m   2547\u001b[0m \u001b[38;5;124;03m            \"col 1\": \"c\",\u001b[39;00m\n\u001b[1;32m   2548\u001b[0m \u001b[38;5;124;03m            \"col 2\": \"d\"\u001b[39;00m\n\u001b[1;32m   2549\u001b[0m \u001b[38;5;124;03m        }}\u001b[39;00m\n\u001b[1;32m   2550\u001b[0m \u001b[38;5;124;03m    ]\u001b[39;00m\n\u001b[1;32m   2551\u001b[0m \n\u001b[1;32m   2552\u001b[0m \u001b[38;5;124;03m    Encoding/decoding a Dataframe using ``'index'`` formatted JSON:\u001b[39;00m\n\u001b[1;32m   2553\u001b[0m \n\u001b[1;32m   2554\u001b[0m \u001b[38;5;124;03m    >>> result = df.to_json(orient=\"index\")\u001b[39;00m\n\u001b[1;32m   2555\u001b[0m \u001b[38;5;124;03m    >>> parsed = json.loads(result)\u001b[39;00m\n\u001b[1;32m   2556\u001b[0m \u001b[38;5;124;03m    >>> json.dumps(parsed, indent=4)  # doctest: +SKIP\u001b[39;00m\n\u001b[1;32m   2557\u001b[0m \u001b[38;5;124;03m    {{\u001b[39;00m\n\u001b[1;32m   2558\u001b[0m \u001b[38;5;124;03m        \"row 1\": {{\u001b[39;00m\n\u001b[1;32m   2559\u001b[0m \u001b[38;5;124;03m            \"col 1\": \"a\",\u001b[39;00m\n\u001b[1;32m   2560\u001b[0m \u001b[38;5;124;03m            \"col 2\": \"b\"\u001b[39;00m\n\u001b[1;32m   2561\u001b[0m \u001b[38;5;124;03m        }},\u001b[39;00m\n\u001b[1;32m   2562\u001b[0m \u001b[38;5;124;03m        \"row 2\": {{\u001b[39;00m\n\u001b[1;32m   2563\u001b[0m \u001b[38;5;124;03m            \"col 1\": \"c\",\u001b[39;00m\n\u001b[1;32m   2564\u001b[0m \u001b[38;5;124;03m            \"col 2\": \"d\"\u001b[39;00m\n\u001b[1;32m   2565\u001b[0m \u001b[38;5;124;03m        }}\u001b[39;00m\n\u001b[1;32m   2566\u001b[0m \u001b[38;5;124;03m    }}\u001b[39;00m\n\u001b[1;32m   2567\u001b[0m \n\u001b[1;32m   2568\u001b[0m \u001b[38;5;124;03m    Encoding/decoding a Dataframe using ``'columns'`` formatted JSON:\u001b[39;00m\n\u001b[1;32m   2569\u001b[0m \n\u001b[1;32m   2570\u001b[0m \u001b[38;5;124;03m    >>> result = df.to_json(orient=\"columns\")\u001b[39;00m\n\u001b[1;32m   2571\u001b[0m \u001b[38;5;124;03m    >>> parsed = json.loads(result)\u001b[39;00m\n\u001b[1;32m   2572\u001b[0m \u001b[38;5;124;03m    >>> json.dumps(parsed, indent=4)  # doctest: +SKIP\u001b[39;00m\n\u001b[1;32m   2573\u001b[0m \u001b[38;5;124;03m    {{\u001b[39;00m\n\u001b[1;32m   2574\u001b[0m \u001b[38;5;124;03m        \"col 1\": {{\u001b[39;00m\n\u001b[1;32m   2575\u001b[0m \u001b[38;5;124;03m            \"row 1\": \"a\",\u001b[39;00m\n\u001b[1;32m   2576\u001b[0m \u001b[38;5;124;03m            \"row 2\": \"c\"\u001b[39;00m\n\u001b[1;32m   2577\u001b[0m \u001b[38;5;124;03m        }},\u001b[39;00m\n\u001b[1;32m   2578\u001b[0m \u001b[38;5;124;03m        \"col 2\": {{\u001b[39;00m\n\u001b[1;32m   2579\u001b[0m \u001b[38;5;124;03m            \"row 1\": \"b\",\u001b[39;00m\n\u001b[1;32m   2580\u001b[0m \u001b[38;5;124;03m            \"row 2\": \"d\"\u001b[39;00m\n\u001b[1;32m   2581\u001b[0m \u001b[38;5;124;03m        }}\u001b[39;00m\n\u001b[1;32m   2582\u001b[0m \u001b[38;5;124;03m    }}\u001b[39;00m\n\u001b[1;32m   2583\u001b[0m \n\u001b[1;32m   2584\u001b[0m \u001b[38;5;124;03m    Encoding/decoding a Dataframe using ``'values'`` formatted JSON:\u001b[39;00m\n\u001b[1;32m   2585\u001b[0m \n\u001b[1;32m   2586\u001b[0m \u001b[38;5;124;03m    >>> result = df.to_json(orient=\"values\")\u001b[39;00m\n\u001b[1;32m   2587\u001b[0m \u001b[38;5;124;03m    >>> parsed = json.loads(result)\u001b[39;00m\n\u001b[1;32m   2588\u001b[0m \u001b[38;5;124;03m    >>> json.dumps(parsed, indent=4)  # doctest: +SKIP\u001b[39;00m\n\u001b[1;32m   2589\u001b[0m \u001b[38;5;124;03m    [\u001b[39;00m\n\u001b[1;32m   2590\u001b[0m \u001b[38;5;124;03m        [\u001b[39;00m\n\u001b[1;32m   2591\u001b[0m \u001b[38;5;124;03m            \"a\",\u001b[39;00m\n\u001b[1;32m   2592\u001b[0m \u001b[38;5;124;03m            \"b\"\u001b[39;00m\n\u001b[1;32m   2593\u001b[0m \u001b[38;5;124;03m        ],\u001b[39;00m\n\u001b[1;32m   2594\u001b[0m \u001b[38;5;124;03m        [\u001b[39;00m\n\u001b[1;32m   2595\u001b[0m \u001b[38;5;124;03m            \"c\",\u001b[39;00m\n\u001b[1;32m   2596\u001b[0m \u001b[38;5;124;03m            \"d\"\u001b[39;00m\n\u001b[1;32m   2597\u001b[0m \u001b[38;5;124;03m        ]\u001b[39;00m\n\u001b[1;32m   2598\u001b[0m \u001b[38;5;124;03m    ]\u001b[39;00m\n\u001b[1;32m   2599\u001b[0m \n\u001b[1;32m   2600\u001b[0m \u001b[38;5;124;03m    Encoding with Table Schema:\u001b[39;00m\n\u001b[1;32m   2601\u001b[0m \n\u001b[1;32m   2602\u001b[0m \u001b[38;5;124;03m    >>> result = df.to_json(orient=\"table\")\u001b[39;00m\n\u001b[1;32m   2603\u001b[0m \u001b[38;5;124;03m    >>> parsed = json.loads(result)\u001b[39;00m\n\u001b[1;32m   2604\u001b[0m \u001b[38;5;124;03m    >>> json.dumps(parsed, indent=4)  # doctest: +SKIP\u001b[39;00m\n\u001b[1;32m   2605\u001b[0m \u001b[38;5;124;03m    {{\u001b[39;00m\n\u001b[1;32m   2606\u001b[0m \u001b[38;5;124;03m        \"schema\": {{\u001b[39;00m\n\u001b[1;32m   2607\u001b[0m \u001b[38;5;124;03m            \"fields\": [\u001b[39;00m\n\u001b[1;32m   2608\u001b[0m \u001b[38;5;124;03m                {{\u001b[39;00m\n\u001b[1;32m   2609\u001b[0m \u001b[38;5;124;03m                    \"name\": \"index\",\u001b[39;00m\n\u001b[1;32m   2610\u001b[0m \u001b[38;5;124;03m                    \"type\": \"string\"\u001b[39;00m\n\u001b[1;32m   2611\u001b[0m \u001b[38;5;124;03m                }},\u001b[39;00m\n\u001b[1;32m   2612\u001b[0m \u001b[38;5;124;03m                {{\u001b[39;00m\n\u001b[1;32m   2613\u001b[0m \u001b[38;5;124;03m                    \"name\": \"col 1\",\u001b[39;00m\n\u001b[1;32m   2614\u001b[0m \u001b[38;5;124;03m                    \"type\": \"string\"\u001b[39;00m\n\u001b[1;32m   2615\u001b[0m \u001b[38;5;124;03m                }},\u001b[39;00m\n\u001b[1;32m   2616\u001b[0m \u001b[38;5;124;03m                {{\u001b[39;00m\n\u001b[1;32m   2617\u001b[0m \u001b[38;5;124;03m                    \"name\": \"col 2\",\u001b[39;00m\n\u001b[1;32m   2618\u001b[0m \u001b[38;5;124;03m                    \"type\": \"string\"\u001b[39;00m\n\u001b[1;32m   2619\u001b[0m \u001b[38;5;124;03m                }}\u001b[39;00m\n\u001b[1;32m   2620\u001b[0m \u001b[38;5;124;03m            ],\u001b[39;00m\n\u001b[1;32m   2621\u001b[0m \u001b[38;5;124;03m            \"primaryKey\": [\u001b[39;00m\n\u001b[1;32m   2622\u001b[0m \u001b[38;5;124;03m                \"index\"\u001b[39;00m\n\u001b[1;32m   2623\u001b[0m \u001b[38;5;124;03m            ],\u001b[39;00m\n\u001b[1;32m   2624\u001b[0m \u001b[38;5;124;03m            \"pandas_version\": \"1.4.0\"\u001b[39;00m\n\u001b[1;32m   2625\u001b[0m \u001b[38;5;124;03m        }},\u001b[39;00m\n\u001b[1;32m   2626\u001b[0m \u001b[38;5;124;03m        \"data\": [\u001b[39;00m\n\u001b[1;32m   2627\u001b[0m \u001b[38;5;124;03m            {{\u001b[39;00m\n\u001b[1;32m   2628\u001b[0m \u001b[38;5;124;03m                \"index\": \"row 1\",\u001b[39;00m\n\u001b[1;32m   2629\u001b[0m \u001b[38;5;124;03m                \"col 1\": \"a\",\u001b[39;00m\n\u001b[1;32m   2630\u001b[0m \u001b[38;5;124;03m                \"col 2\": \"b\"\u001b[39;00m\n\u001b[1;32m   2631\u001b[0m \u001b[38;5;124;03m            }},\u001b[39;00m\n\u001b[1;32m   2632\u001b[0m \u001b[38;5;124;03m            {{\u001b[39;00m\n\u001b[1;32m   2633\u001b[0m \u001b[38;5;124;03m                \"index\": \"row 2\",\u001b[39;00m\n\u001b[1;32m   2634\u001b[0m \u001b[38;5;124;03m                \"col 1\": \"c\",\u001b[39;00m\n\u001b[1;32m   2635\u001b[0m \u001b[38;5;124;03m                \"col 2\": \"d\"\u001b[39;00m\n\u001b[1;32m   2636\u001b[0m \u001b[38;5;124;03m            }}\u001b[39;00m\n\u001b[1;32m   2637\u001b[0m \u001b[38;5;124;03m        ]\u001b[39;00m\n\u001b[1;32m   2638\u001b[0m \u001b[38;5;124;03m    }}\u001b[39;00m\n\u001b[1;32m   2639\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   2640\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m json\n\u001b[1;32m   2642\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m date_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m orient \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mTypeError\u001b[0m: write() got an unexpected keyword argument 'engine_kwargs'"
     ]
    }
   ],
   "source": [
    "x.to_excel('submission.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa6674e-1f06-4b0d-8e8a-938d0e4665a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
